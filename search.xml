<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CDN学习</title>
      <link href="/posts/53f1b0f5.html"/>
      <url>/posts/53f1b0f5.html</url>
      
        <content type="html"><![CDATA[<h1 id="CDN工作原理"><a href="#CDN工作原理" class="headerlink" title="CDN工作原理"></a>CDN工作原理</h1><h2 id="CDN的产生与作用"><a href="#CDN的产生与作用" class="headerlink" title="CDN的产生与作用"></a>CDN的产生与作用</h2><p>随着时代的发展，网民数量增多，访问路径过长，所以当用户与网站之间的链路被突发的大流量数据拥塞时<br>不同地区的用户访问网站的响应速度存在差异,为了提高用户访问的响应速度、优化现有Internet中信息的流动,需要在用户和服务器间加入中间层CDN。<br>CDN将内容推送到网络边缘，大量的用户访问被分散在网络边缘，不再构成网站出口、互联互通点的资源挤占，也不再需要跨越长距离IP路由，即减少了源服务器的资源占用，企业大大提升了用户访问的响应时间，<strong>从而使用户能以最快的速度，从最接近用户户的地方获得所需的信息</strong>，彻底解决网络拥塞提高响应速度。<br><strong>CDN</strong>(Content Deliverv Network) ，即内容分发网络。其目的是通过在现有的lnteret中增加一层新的CACHE(缓存)层，将网站的内容发布到最接近用户的网络”边缘”的节点，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等原因，提高用户访问网站的响应速度。</p><h2 id="访问源站的过程"><a href="#访问源站的过程" class="headerlink" title="访问源站的过程"></a>访问源站的过程</h2><p>在浏览器中输入一个网址 <em><strong>.com，最终会将该域名解析为一个IP地址<br>DNS：域名系统，Domain Name System，核心作用就是将一个域名解析为IP地址<br>为了更清楚地展示CDN的原理，首先回顾一下不使用缓存直接到源站请求数据的过程：<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710496423309-cf65387c-8386-4580-adc2-3618bc551289.png#averageHue=%23fdfdfd&clientId=ufb51605c-ede8-4&from=paste&height=395&id=u2a17e7db&originHeight=765&originWidth=1205&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=196298&status=done&style=none&taskId=ude12bbdc-dc28-4c2c-8e7f-2aeb9fd1176&title=&width=622" alt="image.png"><br>如上图所示，如果要访问的网站名为:”www.</strong></em>.edu.com”<br>(1) 客户端首先会在本机的hosts文件和hosts缓存中查找该域名对应的IP地址<br>(2) 如果本机中没有此信息，则会到我们的<strong>本地DNS</strong> 进行询问该域名对应的IP地址<br>(3)如果本地DNS中仍然没有该域名的IP信息时，则会由本地DNS依次向<strong>根DNS、顶级域ONS、权威DNS <strong>进行询问，最终</strong>本地DNS</strong>将IP地址发送给客户端<br>(4) 客户端通过IP地址向远程的源站服务器发出HTTP请求并获取相应的数据内容<br>以上是通过DNS的<strong>选代解析</strong> 模式获取域名对应的IP地址并发送HTTP请求的过程。源站的提供商通过配权威DNS将源站的域名与提供服务的服务器主机进行绑定，使客户端通过DNS服务可以顺利地获取源站域名对应的IP地址并通过IP地址与源站进行通信。</p><h2 id="DNS的记录类型"><a href="#DNS的记录类型" class="headerlink" title="DNS的记录类型"></a>DNS的记录类型</h2><blockquote><p>域名 — &gt;  IP地址</p></blockquote><p>在DNS系统中，最常见的资源记录方式是lnternet类记录，该记录由包含4个字段的数据构成: Name、Value、Type、TTL。其中Name和Value可以理为一对键值对，但是其具体含义取决于Type的类型，TTL记录了该条记录应当从缓存中删除的时间。在资源记录的类型中中，最为常见且重要的类型Type主要有:<br><strong>A记录（Address）</strong><br><strong>A记录用于描述目标域名到IP地址的映射关系</strong>，将目标域名与A记录的Name字段进行匹配，将成功匹配的记录的Value字段的内容IP地址)输出到DNS回应报文中<br><strong>NS记录（Name Server）</strong><br><strong>NS记录用于描述目标域名到负责解析该域名的DNS的映射关系</strong>，根据目标域名对NS记录的Name字段进行匹配，将成功匹配的记录的Value字段(负责解析目标域名的DNS的IP地址) 输出到DNS回应报文中<br><strong>CNAME记录</strong><br><strong>CNAME记录用于描述目的域名和别名的对应关系</strong>，如果说A记录可以将目标域名转换为对应主机的IP地址，那么CNAME记录则可以将一个域名（别名）转换为另一个域名，如果多条CNAME记录指向同一个域名，则可以将多个不同的域名的请求指向同一台服务器主机。并且，CNAME记录通常还对应了一条A记录，用于提供被转换的域名的IP地址。</p><h2 id="通过CDN获取缓存内容的过程"><a href="#通过CDN获取缓存内容的过程" class="headerlink" title="通过CDN获取缓存内容的过程"></a>通过CDN获取缓存内容的过程</h2><p><strong>CDN将我们对源站的请求导向了距离用户较近的最优缓存节点，而非源站。</strong>    <strong>主要是静态资源，数据交互（写入）还是 —-&gt; 源站</strong><br>下图所示是通过CDN进行请求响应的过程图。通过图中可以看出：<br>在DNS解析域名时新增了一个<strong>全局负载均系统(GSLB)<strong>，GSLB的主要功能是根据用户的本地DNS(通常距离用户的物理位置较近) 的IP地址判断用户的位置，筛选出距离用户较近的</strong>本地负载均衡系统(SLB)<strong>，并将该SLB的IP地址作为结果返回给本地DNS。<br>SLB主要负责判断</strong>缓存服务器集群</strong> 中是否包含用户请求的资源数据，如果缓存服务器中存在请求的资源，则根据缓存服务器集群中节点的健康程度、负载量、连接数等因素筛选出最优的缓存节点，并将HTTP请求重定向到最优的缓存节点上。<br>GSLB : Global Server Load Balancing，全局负载均衡服务器<br>SLB(Server load balancing): 负载均衡服务器是对集群内物理主机的负载均衡，而GSLB是对物理集群的负载均衡。<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710503752532-320becb7-40a7-4ac5-bd8f-cd845199fc92.png#averageHue=%23fbfafa&clientId=ufb51605c-ede8-4&from=paste&height=665&id=u63f59642&originHeight=831&originWidth=656&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=197784&status=done&style=none&taskId=ud2e43d41-cdd3-4240-9cb2-b3c1be5da38&title=&width=524.8" alt="image.png" style="zoom:80%;" /><br>为了更清晰地说明CDN的工作原理，下面以客户端发起对”<a href="http://www.edu.lagou.com/index.html%22%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%E4%B8%BA%E4%BE%8B%E8%BF%9B%E8%A1%8C%E8%AF%B4%E6%98%8E">www.edu.lagou.com/index.html&quot;的HTTP请求为例进行说明</a>:</p><ol><li>用户发起对“<a href="http://www.edu.lagou.com/index.html%22%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%EF%BC%8C%E9%A6%96%E5%85%88%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87%60%E6%9C%AC%E5%9C%B0DNS%60%E9%80%9A%E8%BF%87%E9%80%81%E4%BB%A3%E8%A7%A3%E6%9E%90%22%E7%9A%84%E6%96%B9%E5%BC%8F%E8%8E%B7%E5%8F%96%E5%9F%9F%E5%90%8D%22edu.lagou.com%22%E7%9A%84IP%E5%9C%B0%E5%9D%80">www.edu.lagou.com/index.html&quot;的HTTP请求，首先需要通过`本地DNS`通过送代解析&quot;的方式获取域名&quot;edu.lagou.com&quot;的IP地址</a></li><li>如果本地DNS的缓存中没有该域名的记录，则向<code>根DNS</code>发送DNS查询报文</li><li><code>根DNS</code>发现域名的前缀为”com”，则给出负责解析<code>com</code>的<code>顶级DNS</code>的IP地址;</li><li>本地DNS向<code>顶级DNS</code>发送DNS查询报文</li><li><code>顶级DNS</code>发现域名的前缀为”lagou.com”，在本地记录中查找负责该前缀的<code>权威DNS</code>的IP地址并进行回复</li><li>本地DNS向<code>权威DNS</code>发送DNS查询报文;</li><li>权威DNS查找到一条NAME宇段为”edu.lagou.com”的<code>CNAME记录</code>(由服务提供者配置，阿里云、网宿科技)，该记录的Value字段为”edu.lagou.cdn.com”；并且还找到另一条 NAME 字段为 “edu.lagou.cdn.com”的A记录（域名 –&gt; IP），该记录的 Value字段为 GSLB 的IP地址；</li><li>本地DNS向GSLB发送DNS查询报文</li><li>GSLB根据<code>本地DNS</code> 的IP地址判断用户的大致位置为北京，筛选出位于海淀区且综合考量最优的SLB的IP地址填入DNS回应报文，作为DNS查询的最终结果;</li><li>本地DNS回复客户端的DNS请求，将上一步的IP地址作为最终结果回复给客户端</li><li>客户端根据IP地址向SLB发送HTTP请求:”<a href="http://www.edu.lagou.com/index.html">www.edu.lagou.com/index.html</a>“</li><li>SLB综合考虑缓存服务器集群中各个节点的资源限制条件、健康度、负载情况等因素，筛选出最优的缓存节点后回应客户端的HTTP请求(状态码为302，重定向地址为最优缓存节点的IP地址) ;</li><li>客户端接收到SLB的HTTP回复后，重定向到该缓存节点上;</li><li>缓存节点判断请求的资源是否存在、过期，将缓存的资源直接回复给客户端，否则到源站进行数据更新再回复</li></ol><p><strong>总结</strong>：<br>一个普通的DNS请求包括如下步骤：① 用户提交域名 ②客户端解析域名 ③DNS服务器解析出IP ④客户端请求IP ⑤返回结束<br>加入了GSLB的请求步骤如下：①提交域名 ②客户端解析域名 ③NS(name server，将域名解析到另一个域名) 解析到GSLB ④GSLB解析并返回IP ⑤客户端请求IP ⑥返回结束</p><h2 id="CDN的网络架构"><a href="#CDN的网络架构" class="headerlink" title="CDN的网络架构"></a>CDN的网络架构</h2><p>CDN网络架构主要由两大部分，分别是 中心 和 边缘两部分：<br>中心指 CDN网关中心和DNS重定向解析中心，负责全局负载均衡，设备系统安装在管理中心机房  —- GSLB<br>边缘主要指异地节点、CDN分发的载体，主要由Cache和负载均衡器等组成<br>中心：CDN网关中心、DNS重定向解析中心<br>边缘：Cache、负载均衡器<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710508708227-5b82d25a-6645-4fa3-a471-08bb19e76a0a.png#averageHue=%23fdfdfd&clientId=ufb51605c-ede8-4&from=paste&height=469&id=ua4df329b&originHeight=586&originWidth=1248&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=230674&status=done&style=none&taskId=u179055ea-208b-4888-a95d-3b1af66df84&title=&width=998.4" alt="image.png"><br>当用户访问加入CDN服务的网站时，域名解析请求将最终交全局负载均衡DN9进行处理。全局负载均衡DNS通过一组预先定义好的策略，将当时最接近用户的节点地址提供给用户，使用户能够得到快速的服务。同时，它还与分布在世界各地的所有CDN节点保持通信，搜集各节点的通信状态，确保不将用户的请求分配到不可用的CDN节点上，实际上是通过DNS做全局负载均衡<br>对于普通的Internet用户来进，每个CDN节点就相当于一个放置在它周围的WEB。通过全局负载均衡DNS的控制，用户的请求被透明地指向离他最近的节点，节点中CDN服务器会像网站的原始服务器一样，响应用户的请求。由于它离用户更近，因而响应时间必然更快。<br><strong>每个CDN节点由两部分组成: 负载均衡设备和高速缓存服务器</strong><br>负载均衡设备负责每个节点中各个Cache的负载均衡，保节点的工作效率;同时，负载均衡设备还负责收集节点与周围环境的信息，保持与全局负载DNS的通信，实现整个系统的负载均衡。<br>高速缓存服务器(Cache) 负责存储客户网站的大量信息，就像一个靠近用户的网站服务器一样响应本地用户的访问请求<br>理论上，最简单的CDN网络有一个负责全局负载均衡的DNS和各节点一台Cache，即可运行。DNS支持根据用户源IP地址解析不同的IP，实现就近访问。为了保证高可用性等，需要监视各节点的流量、健康状况等。一个节点的单台ahe承载数量不够时，才需要多合Cache，多合Cache同时工作，才需要负载均衡器，使Cache群协同工作。</p><h2 id="CDN相关术语"><a href="#CDN相关术语" class="headerlink" title="CDN相关术语"></a>CDN相关术语</h2><ol><li>源站</li></ol><p>指发布内容的原始站点，也就是做CDN之前客户真正的服务器</p><ol start="2"><li>边缘服务器（Edge Server）</li></ol><p>对于边缘服务器，CDN提供了就近访问的能力，边缘服务器节点就是 实际提供给用户就近连接、访问的服务器</p><ol start="3"><li>CDN命中率</li></ol><p>CDN一般提供的是静态加速能力，静态加速能力通常通过缓存架构来实现，CDN命中指的是CDN服务器有该资源缓存存在，请求到达CDN节点时，CDN服务器可以在本地缓存获取资源直接返回客户端，如果没有命中，则需要CDN节点到源站获取资源。CDN命中的概率即CDN命中率</p><ol start="4"><li>回源</li></ol><p>当CDN没有命中缓存，需要到源站去获取资源，这个过程称为回源，回源需要从CDN节点层层代理访问，最终到源站获取资源</p><ol start="5"><li>中间层服务器</li></ol><p>边缘节点比较松散，因此存在缓存穿透的问题。为了避免回流引起的性能大幅下降，在CDN的中间层服务器将多个CDN节点的访问进行收敛，从而大幅提高命中率</p><h1 id="CDN应用场景"><a href="#CDN应用场景" class="headerlink" title="CDN应用场景"></a>CDN应用场景</h1><h2 id="网页站点加速"><a href="#网页站点加速" class="headerlink" title="网页站点加速"></a>网页站点加速</h2><p>网站或者应用App的主要业务为图片和小文件下载，包括各类型图片、html、css、js小文件等<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710509574060-ec86db5f-e644-4c7e-bf96-1e397cd58fc4.png#averageHue=%23f6f6f5&clientId=ufb51605c-ede8-4&from=paste&height=611&id=uaf9aeaa4&originHeight=764&originWidth=1518&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=522979&status=done&style=none&taskId=ue03f08b7-ab92-42e4-a35c-c0c696a384d&title=&width=1214.4" alt="image.png"></p><h2 id="下载加速"><a href="#下载加速" class="headerlink" title="下载加速"></a>下载加速</h2><p>网站或者应用App的主要业务为大文件下载，平均单个文件大小在20M以上，如游戏、各类客户端下载和App下载商店等<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710509801466-4341952e-e198-4eb3-963d-6ceae0104893.png#averageHue=%23f5f5f4&clientId=ufb51605c-ede8-4&from=paste&height=612&id=u4b6e60b9&originHeight=765&originWidth=1521&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=518303&status=done&style=none&taskId=u911953e9-66d9-4e5b-b419-d8c922b5b5c&title=&width=1216.8" alt="image.png"></p><h2 id="视频点播"><a href="#视频点播" class="headerlink" title="视频点播"></a>视频点播</h2><p>网站或应用App的主要业务为视频点播或短视频类。支持MP4、FLV等主流视频格式<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710509811139-972b562c-a444-4145-9e2b-31dbd672e17a.png#averageHue=%23f7f7f6&clientId=ufb51605c-ede8-4&from=paste&height=612&id=u14a75843&originHeight=765&originWidth=1528&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=450559&status=done&style=none&taskId=u92dc9865-bfbf-4df9-8c53-3205365ff18&title=&width=1222.4" alt="image.png"></p><h2 id="视频直播"><a href="#视频直播" class="headerlink" title="视频直播"></a>视频直播</h2><p><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710509882538-3f31a8a6-5abb-466c-96bb-b330ddba0ac2.png#averageHue=%23efe9e2&clientId=ufb51605c-ede8-4&from=paste&height=614&id=uede28570&originHeight=768&originWidth=1553&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=612206&status=done&style=none&taskId=u963ef20e-dfff-453d-aca6-3a67eee7b5b&title=&width=1242.4" alt="image.png"></p><h2 id="移动加速"><a href="#移动加速" class="headerlink" title="移动加速"></a>移动加速</h2><p><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710509894214-cfc4c4f1-8ff2-4e16-af40-7cff19cb319b.png#averageHue=%23f6f5f5&clientId=ufb51605c-ede8-4&from=paste&height=612&id=u60c262d0&originHeight=765&originWidth=1561&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=541689&status=done&style=none&taskId=u1b227060-b663-4668-84b2-4a7d137c656&title=&width=1248.8" alt="image.png"></p><h1 id="CDN实战"><a href="#CDN实战" class="headerlink" title="CDN实战"></a>CDN实战</h1><p>阿里云CDN部署：<a href="https://help.aliyun.com/zh/cdn/use-cases/best-practices/?spm=a2c4g.11186623.0.0.2e702efeACMrmL">https://help.aliyun.com/zh/cdn/use-cases/best-practices/?spm=a2c4g.11186623.0.0.2e702efeACMrmL</a><br>腾讯云CDN部署：<a href="https://cloud.tencent.com/document/product/228/3149">https://cloud.tencent.com/document/product/228/3149</a></p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/4a17b156.html"/>
      <url>/posts/4a17b156.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Nginx性能优化</title>
      <link href="/posts/598b5c3.html"/>
      <url>/posts/598b5c3.html</url>
      
        <content type="html"><![CDATA[<p>Web服务器优化目的：提升处理请求的并发总数、提升响应的效率，对于Nginx的优化更多的是借助于nginx.conf，修改其配置信息。</p><h1 id="优化-Nginx-并发量"><a href="#优化-Nginx-并发量" class="headerlink" title="优化 Nginx 并发量"></a>优化 Nginx 并发量</h1><h2 id="优化Nginx进程数量"><a href="#优化Nginx进程数量" class="headerlink" title="优化Nginx进程数量"></a>优化Nginx进程数量</h2><p>配置参数如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">worker_processes</span> <span class="number">1</span>; <span class="comment"># 指定 Nginx 要开启的进程数，结尾的数字就是进程的个数，可以为 auto</span></span><br></pre></td></tr></table></figure><p>这个参数调整的是 Nginx 服务的 worker 进程数，Nginx 有 Master 进程和 worker 进程之分，Master 为管理进程、真正接待“顾客”的是 worker 进程。<br>进程个数的策略：worker 进程数可以设置为等于 CPU 的核数。高流量高并发场合也可以考虑将进程数提高至 CPU 核数 x 2。这个参数除了要和 CPU 核数匹配之外，也与硬盘存储的数据及系统的负载有关，设置为 CPU 核数是个好的起始配置，也是官方建议的。<br>当然，如果想省麻烦也可以配置为 <code>worker_processes auto;</code>，将由 Nginx 自行决定 worker 数量。当访问量快速增加时，Nginx 就会临时 fork 新进程来缩短系统的瞬时开销和降低服务的时间。</p><h2 id="进程绑定CPU"><a href="#进程绑定CPU" class="headerlink" title="进程绑定CPU"></a>进程绑定CPU</h2><p>默认情况下，Nginx 的多个进程有可能运行在同一个 CPU 核上，导致 Nginx 进程使用硬件的资源不均，这就需要制定进程分配到指定的 CPU 核上处理，达到充分有效利用硬件的目的。配置参数如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">worker_processes</span> <span class="number">4</span>;</span><br><span class="line"><span class="attribute">worker_cpu_affinity</span> <span class="number">0001</span> <span class="number">0010</span> <span class="number">0100</span> <span class="number">1000</span>;</span><br></pre></td></tr></table></figure><p>其中 <code>worker_cpu_affinity</code> 就是配置 Nginx 进程与 CPU 亲和力的参数，即把不同的进程分给不同的 CPU 核处理。这里的 <code>0001 0010 0100 1000</code>是掩码，分别代表第1、2、3、4核CPU。上述配置会为每个进程分配一核CPU处理。<br>当然，如果想省麻烦也可以配置 <code>worker_cpu_affinity auto;</code>，将由 Nginx 按需自动分配。</p><h2 id="事件处理模块优化"><a href="#事件处理模块优化" class="headerlink" title="事件处理模块优化"></a>事件处理模块优化</h2><p>Nginx 的连接处理机制在不同的操作系统中会采用不同的 I&#x2F;O 模型，在 linux 下，Nginx 使用 epoll 的 I&#x2F;O 多路复用模型，在 Freebsd 中使用 kqueue 的 I&#x2F;O 多路复用模型，在 Solaris 中使用 &#x2F;dev&#x2F;poll 方式的 I&#x2F;O 多路复用模型，在 Windows 中使用 icop，等等。<br>配置如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">  <span class="attribute">use</span> <span class="literal">epoll</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>events</code> 指令是设定 Nginx 的工作模式及连接数上限。<code>use</code>指令用来指定 Nginx 的工作模式。Nginx 支持的工作模式有 select、 poll、 kqueue、 epoll 、 rtsig 和&#x2F; dev&#x2F;poll。当然，也可以不指定事件处理模型，Nginx 会自动选择最佳的事件处理模型。</p><h2 id="单个进程允许的客户端最大连接数"><a href="#单个进程允许的客户端最大连接数" class="headerlink" title="单个进程允许的客户端最大连接数"></a>单个进程允许的客户端最大连接数</h2><p>通过调整控制连接数的参数来调整 Nginx 单个进程允许的客户端最大连接数。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">  <span class="attribute">worker_connections</span> <span class="number">20480</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>worker_connections</code> 也是个事件模块指令，用于定义 Nginx 每个进程的最大连接数，默认是 1024。<br>最大连接数的计算公式如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">max_clients</span> = worker_processes * worker_connections;</span><br></pre></td></tr></table></figure><p>如果作为反向代理，因为浏览器默认会开启 2 个连接到 server，而且 Nginx 还会使用fds（file descriptor）从同一个连接池建立连接到 upstream 后端。则最大连接数的计算公式如下：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">max_clients</span> = worker_processes * worker_connections / <span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>另外，进程的最大连接数受 Linux 系统进程的最大打开文件数限制，在执行操作系统命令 <code>ulimit -HSn 65535</code>或配置相应文件后，<code>worker_connections</code>的设置才能生效。</p><blockquote><p>ulimit -a 显示当前所有的资源限制 ulimit -H 设置硬件资源限制 ulimit -S 设置软件资源限制 ulimit -n 设置进程最大打开文件描述符数</p></blockquote><h2 id="配置获取更多连接数"><a href="#配置获取更多连接数" class="headerlink" title="配置获取更多连接数"></a>配置获取更多连接数</h2><p>默认情况下，Nginx 进程只会在一个时刻接收一个新的连接，我们可以配置 <code>multi_accept</code>为 <code>on</code>，实现在一个时刻内可以接收多个新的连接，提高处理效率。该参数默认是 <code>off</code>，<strong>建议开启。</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">  <span class="attribute">multi_accept</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="配置-worker-进程的最大打开文件数"><a href="#配置-worker-进程的最大打开文件数" class="headerlink" title="配置 worker 进程的最大打开文件数"></a>配置 worker 进程的最大打开文件数</h2><p>调整配置 Nginx worker 进程的最大打开文件数，这个控制连接数的参数为 <code> worker_rlimit_nofile</code>。该参数的实际配置如下:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">worker_rlimit_nofile</span> <span class="number">65535</span>;</span><br></pre></td></tr></table></figure><p>可设置为系统优化后的 <code>ulimit -HSn</code>的结果</p><h2 id="TCP优化"><a href="#TCP优化" class="headerlink" title="TCP优化"></a>TCP优化</h2><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">  <span class="attribute">sendfile</span> <span class="literal">on</span>;</span><br><span class="line">  <span class="attribute">tcp_nopush</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">keepalive_timeout</span> <span class="number">120</span>;</span><br><span class="line">  <span class="attribute">tcp_nodelay</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一行的 <code>sendfile</code> 配置可以提高 Nginx 静态资源托管效率。sendfile 是一个系统调用，直接在内核空间完成文件发送，不需要先 read 再 write，没有上下文切换开销。<br>TCP_NOPUSH 是 FreeBSD 的一个 socket 选项，对应 Linux 的 TCP_CORK，Nginx 里统一用 <code>tcp_nopush</code> 来控制它，并且只有在启用了 <code>sendfile</code> 之后才生效。启用它之后，数据包会累计到一定大小之后才会发送，减小了额外开销，提高网络效率。<br>TCP_NODELAY 也是一个 socket 选项，启用后会禁用 Nagle 算法，尽快发送数据，某些情况下可以节约 200ms。Nginx 只会针对处于 keep-alive 状态的 TCP 连接才会启用 <code>tcp_nodelay</code>。</p><blockquote><p>Nagle 算法原理是：在发出去的数据还未被确认之前，新生成的小数据先存起来，凑满一个 MSS 或者等到收到确认后再发送</p></blockquote><h2 id="优化连接参数"><a href="#优化连接参数" class="headerlink" title="优化连接参数"></a>优化连接参数</h2><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">  <span class="attribute">client_header_buffer_size</span> <span class="number">32k</span>;</span><br><span class="line">  <span class="attribute">client_max_body_size</span> <span class="number">4m</span>;</span><br><span class="line">  <span class="attribute">client_body_buffer_size</span> <span class="number">10m</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这部分更多是根据具体业务场景来决定的。<br>例如 <code>client_max_body_size</code>用来决定请求体的大小，用来限制上传文件的大小。上面列出的参数可以作为起始参数。</p><h1 id="压缩优化"><a href="#压缩优化" class="headerlink" title="压缩优化"></a>压缩优化</h1><p>我们在上线前，代码（JS、CSS 和 HTML）会做压缩，图片也会做压缩（PNGOUT、Pngcrush、JpegOptim、Gifsicle 等）。对于文本文件，在服务端发送响应之前进行 GZip 压缩也很重要，通常压缩后的文本大小会减小到原来的 1&#x2F;4 - 1&#x2F;3。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">  <span class="attribute">gzip</span> <span class="literal">on</span>;<span class="comment">#决定是否开启gzip模块，on表示开启，off表示关闭；</span></span><br><span class="line">  <span class="attribute">gzip_buffers</span> <span class="number">4</span> <span class="number">16k</span>;<span class="comment">#设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间,param2:int(k) 后面单位是k。这里设置以16k为单位,按照原始数据大小以16k为单位的4倍申请内存</span></span><br><span class="line">  <span class="attribute">gzip_comp_level</span> <span class="number">6</span>;<span class="comment">#设置gzip压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大；等级1-9，最小的压缩最快 但是消耗cpu</span></span><br><span class="line">  <span class="attribute">gzip_http_version</span> <span class="number">1</span>.<span class="number">0</span>;<span class="comment">#压缩版本，识别http协议的版本,早起浏览器可能不支持gzip自解压,用户会看到乱码</span></span><br><span class="line">  <span class="attribute">gzip_min_length</span> <span class="number">1k</span>;<span class="comment">#设置允许压缩的页面最小字节(从header头的Content-Length中获取) ，当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩。建议大于1k</span></span><br><span class="line">  <span class="attribute">gzip_proxied</span> any;</span><br><span class="line">  <span class="attribute">gzip_vary</span> <span class="literal">on</span>;  <span class="comment">#启用应答头&quot;Vary: Accept-Encoding&quot;，该选项可以让前端的缓存服务器缓存经过gzip压缩的页面</span></span><br><span class="line">  <span class="attribute">gzip_types</span>   <span class="comment">#指定压缩的类型,线上配置时尽可能配置多的压缩类型!</span></span><br><span class="line">    text/xml application/xml application/atom+xml application/rss+xml application/xhtml+xml image/svg+xml</span><br><span class="line">    text/javascript application/javascript application/x-javascript</span><br><span class="line">    text/x-json application/json application/x-web-app-manifest+json</span><br><span class="line">    text/css text/plain text/x-component</span><br><span class="line">    font/opentype application/x-font-ttf application/vnd.ms-fontobject</span><br><span class="line">    image/x-icon;</span><br><span class="line">  <span class="attribute">gzip_disable</span> <span class="string">&quot;MSIE [1-6]\.(?!.*SV1)&quot;</span>; <span class="comment">#配置禁用gzip条件，支持正则。此处表示ie6及以下不启用gzip（因为ie低版本不支持）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解释如下：<br><code>gzip_vary</code> 用来输出 Vary 响应头，用来解决某些缓存服务的问题。<br><code>gzip_disable</code> 指令接受一个正则表达式，当请求头中的 UserAgent 字段满足这个正则时，响应不会启用 GZip，这是为了解决在某些浏览器启用 GZip 带来的问题。<br>默认 Nginx 只会针对 HTTP&#x2F;1.1 及以上的请求才会启用 GZip，因为部分早期的 HTTP&#x2F;1.0 客户端在处理 GZip 时有 Bug。现在基本上可以忽略这种情况，于是可以指定 gzip_http_version 1.0 来针对 HTTP&#x2F;1.0 及以上的请求开启 GZip。<br>Nginx的Gzip压缩功能虽然好用，但是下面两类文件资源不太建议启用此压缩功能。<br><strong>（1）图片类型资源（还有视频文件）</strong><br>原因：图片如jpg、png文件本身就会有压缩，所以就算开启gzip后，压缩前和压缩后大小没有多大区别，所以开启了反而会白白的浪费资源。（可以试试将一张jpg图片压缩为zip，观察大小并没有多大的变化。虽然zip和gzip算法不一样，但是可以看出压缩图片的价值并不大）<br><strong>（2）大文件资源</strong><br>原因：会消耗大量的cpu资源，且不一定有明显的效果。</p><h1 id="缓存优化"><a href="#缓存优化" class="headerlink" title="缓存优化"></a>缓存优化</h1><h2 id="Nginx代理缓冲"><a href="#Nginx代理缓冲" class="headerlink" title="Nginx代理缓冲"></a>Nginx代理缓冲</h2><p>如果您正在使用 Nginx 反向代理，那么提高性能的一个好方法是使用代理缓冲。 这与 Nginx 如何处理从代理服务器收到的响应有关。 这意味着不会为每个客户端请求查询代理服务器，但如果缓存的数据仍然被认为是有效的，则从缓存中提供数据。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Enables or disables buffering of responses from the proxied server.</span></span><br><span class="line"><span class="attribute">proxy_buffering</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">#proxy buffer cache sizes</span></span><br><span class="line"><span class="attribute">proxy_buffers</span> <span class="number">4</span> <span class="number">4k</span>;  <span class="comment"># 为单个连接设置用于从代理服务器读取响应的缓冲区的数量和大小。默认情况下，缓冲区大小等于一个内存页。这是4K或8K，具体取决于平台。</span></span><br><span class="line"><span class="attribute">proxy_buffer_size</span> <span class="number">4k</span>; <span class="comment"># 设置用于读取从代理服务器接收的响应的第一部分的缓冲区大小,这部分通常包含一个小的响应头。默认情况下，缓冲区大小等于一个内存页</span></span><br><span class="line"><span class="attribute">proxy_busy_buffers_size</span> <span class="number">8k</span>;<span class="comment">#nginx在收到服务器数据后，会分配一部分缓冲区来用于向客户端发送数据。这个缓冲区大小是由proxy_busy_buffers_size决定的。大小通常是proxy_buffers单位大小的两倍。官网默认是8k|16k。</span></span><br></pre></td></tr></table></figure><h2 id="浏览器本地缓存静态数据"><a href="#浏览器本地缓存静态数据" class="headerlink" title="浏览器本地缓存静态数据"></a>浏览器本地缓存静态数据</h2><p>静态资源优化，可以减少连接请求数，同时也不需要对这些资源请求打印日志。但副作用是资源更新可能无法及时。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="comment"># 图片、视频</span></span><br><span class="line">    <span class="section">location</span> <span class="regexp">~ .*\.(gif|jpg|jpeg|png|bmp|swf|flv|mp4|ico)$</span> &#123;</span><br><span class="line">      <span class="attribute">expires</span> <span class="number">30d</span>; //定义客户端缓存时间为30天</span><br><span class="line">      <span class="attribute">access_log</span> <span class="literal">off</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 字体</span></span><br><span class="line">    <span class="section">location</span> <span class="regexp">~ .*\.(eot|ttf|otf|woff|svg)$</span> &#123;</span><br><span class="line">      <span class="attribute">expires</span> <span class="number">30d</span>;</span><br><span class="line">      <span class="attribute">access_log</span> <span class="literal">off</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># js、css</span></span><br><span class="line">    <span class="section">location</span> <span class="regexp">~ .*\.(js|css)?$</span> &#123;</span><br><span class="line">      <span class="attribute">expires</span> <span class="number">7d</span>;</span><br><span class="line">      <span class="attribute">access_log</span> <span class="literal">off</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
            <tag> 优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx场景实战</title>
      <link href="/posts/a4c75e30.html"/>
      <url>/posts/a4c75e30.html</url>
      
        <content type="html"><![CDATA[<h1 id="Nginx-常见场景"><a href="#Nginx-常见场景" class="headerlink" title="Nginx 常见场景"></a>Nginx 常见场景</h1><h2 id="反向代理详解"><a href="#反向代理详解" class="headerlink" title="反向代理详解"></a>反向代理详解</h2><h3 id="正向-反向代理"><a href="#正向-反向代理" class="headerlink" title="正向&#x2F;反向代理"></a>正向&#x2F;反向代理</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从目标服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向日标服务器转交并日将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。<br>反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置，客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感如到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。</p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>正向代理需要你主动设置代理服务器IP或者域名进行访问，由设置的服务器IP或者域名去获取访问内容并返回；反向代理不需要你做任何没置，直接访问服务器真实IP或者域名反向代理服务器)，但是服务器内部会自动根据访问内容进行跳转(目标服务器)及内容返回，你不知道它最终访问的是哪些机器。<br>正向代理是代理客户端，为客户端收发请求，使真实客户端对服务器不可见；而反向代理是代理服务器端，为服务器收发请求，使真实服务器对客户端不可见。<br>从上面的描述也能看得出来正向代理和反向代理最关键的两点区别：</p><ul><li>是否指向目标服务器</li><li>客户端是否要做设置</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710601530853-d879cb4b-6945-4845-9015-607af1aa6025.png#averageHue=%23070706&clientId=ue2cb431a-c024-4&from=paste&height=406&id=ue1d7c4e0&originHeight=508&originWidth=1236&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=21887&status=done&style=none&taskId=ue5c212f3-d6dd-4541-9e52-a189e917c13&title=&width=988.8" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710601578928-f3d24bf8-1318-425b-99f7-3e5f8b9dca1a.png#averageHue=%23181816&clientId=ue2cb431a-c024-4&from=paste&height=385&id=ud09cc1bd&originHeight=481&originWidth=1261&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=26375&status=done&style=none&taskId=ub396e297-980e-40e3-b9dd-56ec3e08520&title=&width=1008.8" alt="image.png"><br>正向代理于反向代理</p><ul><li>正向代理中，Proxy和Client同属一个LAN，对Server透明</li><li>反向代理中，Proxy和Server同属一个LAN，对Client透明</li></ul><p>实际上proxy在两种代理中做的事都是代为收发请求和响应，不过从结构上来看正好左右互换了下，所以把前者那种代理方式叫做正向代理，后者叫做反向代理。<br><strong>从用途上来区分:</strong></p><ul><li>正向代理: 正向代理用途是为了在防火墙内的局域网提供访问internet的途径，另外还可以使用缓冲特性减少网络使用率</li><li>反向代理: 反向代理的用途是将防火墙后面的服务器提供给internet用户访问，同时还可以完成诸如负载均衡等功能</li></ul><p><strong>从安全性来讲：</strong></p><ul><li>正向代理:正向代理允许客户端通过它访问任意网站并且隐蔽客户端自身，因此你必须采取安全措施来确保仅为经过授权的客户端提供服务</li><li>反向代理:对外是透明的，访问者并不知道自己访问的是代理。对访问者而言，他以为访问的就是原始服务器</li></ul><h4 id="代理用途"><a href="#代理用途" class="headerlink" title="代理用途"></a>代理用途</h4><p>正向代理的使用场景：科学上网（俗称翻墙）<br>有时候，用户想要访问某国外网站，该网站无法在国内直接访问，但是我们可以访问到一个代理服务器，这个代理服务器可以访问到这个国外网站。这样呢，用户对该国外网站的访问就需要通过代理服务器来转发请求，并且该代理服务器也会将请求的响应再返回给用户。这个上网的过程就是用到了正向代理。</p><p>正向代理用途：</p><ul><li><strong>突破访问显示</strong>：通过代理服务器，可以突破自身IP访问限制，访问国外网站等</li><li><strong>提高访问速度</strong>：通常代理服务器都设置一个较大的硬盘缓中区，会将部分请求的响应保存到缓中区中，当其他用户再访问相同的信息时，则直接由缓冲区中取出信息，传给用户，以提高访问速度</li><li><strong>隐藏客户端真实ip</strong>:上网者可以通过正向代理的方法隐藏自己的ip，免受攻击</li></ul><p>反向代理用途：</p><ul><li><strong>隐藏服务器真实地址：</strong>使用反向代理，可以对客户端隐藏服务器的ip地址</li><li><strong>负载均衡：</strong>反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上</li><li><strong>提高访问速度：</strong>反向代理服务器可以对静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度</li><li><strong>提供安全保障：</strong>反向代理服务器可以作为应用层防火墙，为网站提供对基于web的攻走行为(这DoS&#x2F;DDoS) 的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加客和SSL加速 (如SSL终端代理)，提供HTTP访问认证等。</li></ul><h3 id="反向代理实战"><a href="#反向代理实战" class="headerlink" title="反向代理实战"></a>反向代理实战</h3><p>需求一：代理单一目标服务器<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710602186086-5bc3e5d3-3303-4442-b809-61876f27611c.png#averageHue=%23fbfbfb&clientId=ue2cb431a-c024-4&from=paste&height=224&id=uf0a2c141&originHeight=280&originWidth=1243&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=27456&status=done&style=none&taskId=u5a2652d5-27c6-4998-89be-175989cd1ed&title=&width=994.4" alt="image.png"></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span>       <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span>  localhost;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="comment">#配置反向代理服务器</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://192.168.110.176:8080/;</span><br><span class="line">        <span class="comment">#root   /usr/share/nginx/html;</span></span><br><span class="line">        <span class="comment">#index  index.html index.htm;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</span><br><span class="line">    <span class="section">location</span> = /50x.html &#123;</span><br><span class="line">        <span class="attribute">root</span>   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需求二：多个目标服务器<br>访问：<a href="http://localhost/t1">http://localhost/t1</a> 访问：8080服务器<br>访问：<a href="http://localhost/t2">http://localhost/t2</a> 访问：8081服务器<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710602658459-44f6f74d-75bb-4912-a8c5-90a4bbe22337.png#averageHue=%23fdfdfd&clientId=ue2cb431a-c024-4&from=paste&height=424&id=ub4500539&originHeight=530&originWidth=1359&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=43393&status=done&style=none&taskId=u716139b5-e2f8-475a-b9cc-02fe088f00e&title=&width=1087.2" alt="image.png"></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span>       <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span>  localhost;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> /t1 &#123;</span><br><span class="line">        <span class="comment">#配置反向代理服务器</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://192.168.110.176:8080/;</span><br><span class="line">        <span class="comment">#root   /usr/share/nginx/html;</span></span><br><span class="line">        <span class="comment">#index  index.html index.htm;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> /t2 &#123;</span><br><span class="line">        <span class="comment">#配置反向代理服务器</span></span><br><span class="line">        <span class="attribute">proxy_pass</span> http://192.168.110.176:8081/;</span><br><span class="line">        <span class="comment">#root   /usr/share/nginx/html;</span></span><br><span class="line">        <span class="comment">#index  index.html index.htm;</span></span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</span><br><span class="line">    <span class="section">location</span> = /50x.html &#123;</span><br><span class="line">        <span class="attribute">root</span>   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="负载均衡详解"><a href="#负载均衡详解" class="headerlink" title="负载均衡详解"></a>负载均衡详解</h2><p>负载均衡分类：</p><ul><li>客户端的负载均衡</li><li>服务端的负载均衡</li></ul><p>负载均衡的目的：通过负载均衡提升并发能力和响应速度</p><h3 id="负载均衡模块"><a href="#负载均衡模块" class="headerlink" title="负载均衡模块"></a>负载均衡模块</h3><p>第三方模块可以说是Nginx的一大特色。Nginx的内核设计十分小巧，只包含少量的框架代码，丰富的功能依赖于众多的第三方模块实现。Nginx允许用户根据需求定制开发模块，这也大大提高了Nginx的扩展性。<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710602847847-110cf9bc-05d7-4d42-8e7d-6b3319661e9b.png#averageHue=%23e7e9f0&clientId=ue2cb431a-c024-4&from=paste&height=443&id=u864a861a&originHeight=554&originWidth=1216&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=29776&status=done&style=none&taskId=u6659176f-0058-4390-9149-088f07900e5&title=&width=972.8" alt="image.png"></p><p>Nginx经常作为中间层实现反向代理，将请求转发到后端服务器 (Real Server)进行处理。为了让服务在高并发场景下保持高可用与高吞吐量，后端服务器往往以集群的方式分布式部署。集群中包含几台甚至几十台服务器。此时，Nginx需要以某种形式实现后端服务器的负载均衡，合理地分配请求到每台服务器，实现资源利用率的最大化。<br>最简单的做法是采用轮询策略，即每个后端服务器地位相同，轮流地接收用户请求，这也是生产环境中使用最多的一种负载均衡策略。但是，它存在一定的局限性，即假设后端服务器性能有明显差异，性能较高的服务器应该分配更多的请求，性能较低的服务器则应该分配较少的请求。另外，对于某些业务场景要求同一用户的请求必须发到同一台后端服务器，此时简单的轮询策略就不再适用了。Nginx在设计之初就考虑到了众多场景，通过一系列模块实现了丰富的负载均衡策略。</p><h4 id="Nginx负载均衡算法"><a href="#Nginx负载均衡算法" class="headerlink" title="Nginx负载均衡算法"></a>Nginx负载均衡算法</h4><p>Nginx的负载均衡算法主要分为以下几种：</p><ul><li>轮询 (Round-Robin)：简单的轮询机制，Nginx默认配置的负载均衡算法</li><li>加权轮询 (Weighted Round-Robin)：一种改进的轮询算法，通过为每台Real Server设置权重来改变分配到每台机器上请求的概率，适用于服务器硬件配置差别较大的场景</li><li>IP散列(ip_hash)：基于客户端IP的分配方式，通过hash算法确保来自同一客户端的请求总被分配到同一台后端服务器，保证了会话的有效性。此策略适用于有状态的服务</li><li>最少连接数(least_conn)：尽量将请求转发给连接数少的后端服务器。对于某些长连接场景，单个请求占用的时间很长，服务器资源迟迟不释放，导致后端服务器负载较高，这种情况下采用least_conn算法能达到更好的负载均衡效果</li><li>最短响应时间（fair）：根据后端服务器响应时间进行分配，响应时间短的后端服务器优先分配，这种模式适用于对请求延迟要求较高的场景</li><li>基于key的散列算法 (hash key)：与ip_hash一样是基于hash算法的负载均衡算法，但是其更加灵活。用户可以指定不同的key来满足不同的业务需求，同时可以自由选择是使用一致性hash算法还是使用普通hash算法</li></ul><p>以上介绍的负载均衡算法能满足绝大部分用户的使用需求。<strong>其中，Round-Robin、 Weighted Round-Robin、 ip _hash、 least_conn 是Nginx编译时默认自带的</strong>，而fair与基于key的散列算法需要用户安装第三方模块<br>在实际应用中，用户需要结合自身的业务场景进行选择，对于复杂的情况可以组合使用多种算法以达到最佳的负载均衡效果。</p><h4 id="负载均衡配置命令"><a href="#负载均衡配置命令" class="headerlink" title="负载均衡配置命令"></a>负载均衡配置命令</h4><p>反向代理其实就是借助于 upstream 机制<br>Nginx 负载均衡的配置是围绕 ngx_http_upstream_module 提供的<strong>upstream指令</strong>展开的。该指令定义了一组后端服务器列表，这组服务器可以被 proxy_pass、 fastcgipass&#x2F;memcached_pass等指令引用。Nginx不仅支持以P的方式配置服务器地址，也支持域名（Domain）与套接字(UnixSocket)的形式。这里我们以最常用的IP +端口的形式来简要说明不同负载均衡算法下的Upstream配置。<br>（1）轮询算法下的 Upstream 配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> /abc &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://backend/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）加权轮询算法下的 Upstream 配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span> weight=<span class="number">1</span>;  <span class="comment">#weight指明该节点的权重值</span></span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span> weight=<span class="number">2</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span> weight=<span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> /abc &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://backend/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（3）IP散列算法下的 Upstream 配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    ip_hash;   <span class="comment">#指明采用客户端IP散列算法</span></span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> /abc &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://backend/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（4）最少连接数算法下的 Upstream 配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    least_conn;   <span class="comment">#指明采用最少连接数算法</span></span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> /abc &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://backend/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（5）最短响应时间算法下的 Upstream 配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    fair; <span class="comment">#指明采用最短响应时间算法</span></span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> /abc &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://backend/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（6）基于 key 的散列算法下的 Upstream 配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    <span class="attribute">hash</span> <span class="variable">$request_uri</span>;  <span class="comment">#指明以带参数的url为key进行哈希的算法</span></span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> /abc &#123;</span><br><span class="line"><span class="attribute">proxy_pass</span> http://backend/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的配置示例中，我们应该很容易想到，只需要Upstream配置块里指明负载均衡算法，Nginx就会解析出配置指令并采取对应的策略。事实上，每个服务器的配置还包括其他参数，例如：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> backend &#123;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span> weight=<span class="number">1</span> max_fails=<span class="number">3</span> fail_timeout=<span class="number">30s</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.1:80</span> weight=<span class="number">5</span> max_fails=<span class="number">3</span> fail_timeout=<span class="number">30s</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.2:80</span> backup;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">192.168.0.3:80</span> down;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，大多数配置与Nginx的健康检查、失败重试机制有关。各参数的配置意义如下：</p><ul><li>max_fails：在fail_timeout定义的时间段内允许的最大失败次数</li><li>fail_timeout：设置计算最大失败次数的时间段，默认为10s</li><li>backup：指明该节点为备用节点</li><li>down：标记该节点为宕机不可用状态，且不参与负载均衡</li></ul><p>以上配置示例表示在30s内，如果该节点上有超过三次的失败请求，则认为该节点不可用，且在30s内Nginx不会再给该节点分配请求。当所有的节点不可用时，备用节点启用。</p><h3 id="负载均衡实战"><a href="#负载均衡实战" class="headerlink" title="负载均衡实战"></a>负载均衡实战</h3><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attribute">user</span>  nginx;</span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="attribute">error_log</span>  /var/log/nginx/<span class="literal">error</span>.log <span class="literal">warn</span>;</span><br><span class="line"><span class="attribute">pid</span>        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">include</span>       /etc/nginx/mime.types;</span><br><span class="line">    <span class="attribute">default_type</span>  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">log_format</span>  main  <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;<span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;<span class="variable">$http_user_agent</span>&quot; &quot;<span class="variable">$http_x_forwarded_for</span>&quot;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">access_log</span>  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">sendfile</span>        <span class="literal">on</span>;</span><br><span class="line">    <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">    <span class="attribute">keepalive_timeout</span>  <span class="number">65</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gzip  on;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#配置upstream，使用基于权重的轮训</span></span><br><span class="line">    <span class="section">upstream</span> coding&#123;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.110.176:8080</span> weight=<span class="number">2</span>;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">192.168.110.176:8081</span> weight=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#include /etc/nginx/conf.d/*.conf;</span></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">80</span>;</span><br><span class="line">        <span class="attribute">server_name</span>  localhost;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line">        <span class="comment">#access_log  /var/log/nginx/log/host.access.log  main;</span></span><br><span class="line"></span><br><span class="line">        <span class="section">location</span> /sj &#123;</span><br><span class="line">            <span class="comment">#代理集群</span></span><br><span class="line">            <span class="attribute">proxy_pass</span> http://coding/;</span><br><span class="line">            <span class="comment">#root   /usr/share/nginx/html;</span></span><br><span class="line">            <span class="comment">#index  index.html index.htm;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="attribute">error_page</span>   <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span>  /50x.html;</span><br><span class="line">        <span class="section">location</span> = /50x.html &#123;</span><br><span class="line">            <span class="attribute">root</span>   /usr/share/nginx/html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="动静分离详解"><a href="#动静分离详解" class="headerlink" title="动静分离详解"></a>动静分离详解</h2><h3 id="动静分离原理"><a href="#动静分离原理" class="headerlink" title="动静分离原理"></a>动静分离原理</h3><p>为了提高网站的响应速度，减轻程序服务器（Tomcat，Jboss等）的负载，对于静态资源，如图片、js、css等文件，可以在反向代理服务器中进行缓存，这样浏览器在请求一个静态资源时，代理服务器就可以直接处理，而不用将请求转发给后端服务器。对于用户请求的动态文件，如servlet、jsp，则转发给Tomcat，Jboss服务器处理，这就是动静分离。即动态文件与静态文件的分离。<br>动静分离可通过location对请求url进行匹配，将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问。通常将静态资源放到nginx中，动态资源转发到tomcat服务器中。<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710686946483-d14a7666-293a-4fd3-8507-ecf95b9e2b78.png#averageHue=%23fdfcfb&clientId=ue2cb431a-c024-4&from=paste&height=601&id=ub573211c&originHeight=751&originWidth=1335&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=115402&status=done&style=none&taskId=u2650a52a-2ef6-496f-95f3-63000e286e4&title=&width=1068" alt="image.png"></p><h3 id="静态资源实战"><a href="#静态资源实战" class="headerlink" title="静态资源实战"></a>静态资源实战</h3><p><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710686999225-07382f7d-0578-46db-ad94-8e4462bab8b6.png#averageHue=%230a0a09&clientId=ue2cb431a-c024-4&from=paste&height=467&id=uabc179b6&originHeight=584&originWidth=1220&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=61433&status=done&style=none&taskId=u458519c4-580a-4dd9-b15f-e3e0632218e&title=&width=976" alt="image.png"></p><h2 id="限流模块"><a href="#限流模块" class="headerlink" title="限流模块"></a>限流模块</h2><p>限流是指服务端采取一定的手段限制用户请求量。在高并发场景下，限流是保护系统正常运行的重要手段。合理利用Nginx提供的限流功能能让系统在可承受的压力范围内保持最大的吞吐量，提供尽可能多的服务。<br>漏洞模型：<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710687179580-588d424e-2f3a-41d5-8638-19e3ba983b09.png#averageHue=%23fbfaf9&clientId=ue2cb431a-c024-4&from=paste&height=396&id=ua4a86799&originHeight=867&originWidth=1174&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=98480&status=done&style=none&taskId=ube8a9b6d-f5e1-4711-afc5-f628cda56f1&title=&width=536" alt="image.png"></p><h3 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h3><p>限流方式有很多种，这里简要介绍互联网企业中3种常见的限流算法以及实现原理<br>（1）计数器算法（固定窗口算法–&gt;滑动窗口算法）计数器算法是最简单的一种限流算法，大致实现思路是对指定接口设置國值与时间段。例如100r&#x2F;s，每接收一个请求就将当前的count值加1，当1分钟内count值达到100，说明请求数过多，触发限流策略（比如返回429、503等状态码）。当然，每个count值都有过期时间，下一分钟开始时count值又从零开始。通过这种简单的计数方式就能够起到较好的限流作用。但是，这种限流算法的弊端很明显，如果一个用户在第1s的时候就发送100次请求，那么在剩下的100ms内所有的用户都无法访问。<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710687362521-ff266cd4-4a9f-4960-8ed8-43e36cb6033f.png#averageHue=%23f9f1f0&clientId=ue2cb431a-c024-4&from=paste&height=350&id=ue16aa3b5&originHeight=438&originWidth=1404&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=196674&status=done&style=none&taskId=u0e024e4c-87ad-4bfb-b427-50dd7dab2b4&title=&width=1123.2" alt="image.png"><br>（2）漏桶算法漏桶算法也是常用的一种限流算法，核心思想是构造一个用于存储水(请求）的桶，水（请求）以固定的速率从桶底漏出并被处理，当桶存满时水会溢出，即多余的请求会被丢弃。由于桶的漏出速率是固定的，因此可以强行限制处理请求的速率，这也能够很好地保护服务端系统。但是，这种算法并不能有效地利用系统资源，尤其是对于突发性流量，即使此时系统有能力承载也只能以限制的速率处理，溢出桶外的请求依旧会被拒绝。<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710687408652-2ba9ec17-e3d6-429d-aa1e-e6a0195f3262.png#averageHue=%23fcf3f3&clientId=ue2cb431a-c024-4&from=paste&height=446&id=u5fb74f1d&originHeight=557&originWidth=1372&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=147375&status=done&style=none&taskId=u95601937-3c8e-457d-9d2d-5fcbdfceec5&title=&width=1097.6" alt="image.png"><br>（3）令牌桶算法令牌桶算法的设计原理与漏桶算法类似，其也设计了一个桶，只是这个桶不再用于存放请求，而是用来存储令牌。令牌会以固定的速率加入桶，当桶装满时多余的令牌会被丢弃。每个请求到来时都会取走一块令牌并被处理。当桶里的令牌被取完时，触发限流拒绝服务。这种算法下请求的处理速度不是固定的，当桶里有足够的令牌容量时，可以同时处理多个并发请求，因此服务端具备一定的应对突发流量的能力。阿里的Sentinel（流量哨兵）使用的就是令牌桶算法。<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710687442979-d0f7813d-2620-4f9c-b1fc-08f82ed29b80.png#averageHue=%23f9f3f2&clientId=ue2cb431a-c024-4&from=paste&height=678&id=u2556cfe0&originHeight=848&originWidth=1406&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=518364&status=done&style=none&taskId=u719a24d1-3b45-4745-b860-079bdc66a51&title=&width=1124.8" alt="image.png"></p><h3 id="Nginx限流设置"><a href="#Nginx限流设置" class="headerlink" title="Nginx限流设置"></a>Nginx限流设置</h3><p>Nginx 提供两种限流方式，一是控制速率，二是控制并发连接数。<br><a href="">ngx_http_limit_req_module</a>  模块提供限制请求处理速率能力，使用了漏桶算法(leaky bucket)。</p><h4 id="控制速率"><a href="#控制速率" class="headerlink" title="控制速率"></a>控制速率</h4><p>（1）正常流量处理： limit_req_zone<br>在 nginx.conf 的 http 中添加限流配置：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">      <span class="comment"># 每个客户端在每秒内允许最大的请求数是10，超出10就触发限流，自定义返回的错误码</span></span><br><span class="line">     <span class="attribute">limit_req_zone</span> <span class="variable">$binary_remote_addr</span> zone=myRateLimit:<span class="number">10m</span> rate=10r/s;</span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">   <span class="section">location</span> / &#123;</span><br><span class="line">      <span class="comment"># 该location使用的限流策略</span></span><br><span class="line">      <span class="attribute">limit_req</span> zone=myRateLimit;</span><br><span class="line">      <span class="comment"># 触发限流后返回的错误码</span></span><br><span class="line">      <span class="attribute">limit_req_status</span> <span class="number">405</span>;</span><br><span class="line">      <span class="attribute">proxy_pass</span> http://my_upstream;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>该指令定义了一块用于存储访问频次信息的共享内存zone。其各参数意义如下。</p><ul><li><strong>Key：</strong> 限流标识，通常选取请求的某项特征，例如$binary_remote_addr，表示基于 <strong>remote_addr</strong>（客户端IP）来做限流，<strong>binary_</strong> 的目的是压缩内存占用量</li><li><strong>zone：</strong>定义共享内存区来存储访问信息， myRateLimit:10m 表示一个大小为10M，名字为 myRateLimit 的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。</li><li><strong>rate：</strong>用于设置最大访问速率，rate&#x3D;10r&#x2F;s  表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r&#x2F;s 实际上是限制：<strong>每100毫秒处理一个请求。</strong>这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求。</li></ul><p>限流速度为每秒10次请求，如果有10次请求同时到达一个空闲的nginx，他们都能得到执行吗？<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710752927206-86d85acd-9eab-45b3-837a-39a6940b510b.png#averageHue=%23fbf9f9&clientId=u5817dd03-6324-4&from=paste&height=312&id=uf64911a0&originHeight=488&originWidth=793&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=37590&status=done&style=none&taskId=u3f251987-549b-48f5-a624-edc5cc3439c&title=&width=507.4000244140625" alt="image.png"><br>漏桶漏出请求是匀速的，10r&#x2F;s是怎样匀速的呢？<br>每100ms漏出一个请求。在这样的配置下，桶是空的，所有不能实时漏出的请求，都会被拒绝掉。所以如果10次请求同时到达，那么只有一个请求能够得到执行，其它的，都会被拒绝。这不太友好，大部分业务场景下我们希望这10个请求都能得到执行。<br>（2）突发流量处理： limit_req<br>上面例子限制 10r&#x2F;s，如果有时正常流量突然增大，超出的请求将被拒绝，无法处理突发流量，可以结合 **burst **参数使用来解决该问题。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">   <span class="section">location</span> / &#123;</span><br><span class="line">       <span class="comment"># burst表示启用队列，burst的值就是队列的size，不能被执行的都会放入队列中，超出队列的最大size则直接拒绝。</span></span><br><span class="line">       <span class="attribute">limit_req</span> zone=myRateLimit burst=<span class="number">20</span>;</span><br><span class="line">       <span class="attribute">proxy_pass</span> http://my_upstream;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>burst</strong> 译为突发、爆发，表示在超过设定的处理速率后能额外处理的请求数。当 <strong>rate&#x3D;10r&#x2F;s</strong> 时，将1s拆成10份，即每100ms可处理1个请求。<br>此时， <strong>burst&#x3D;20，</strong>若同时有21个请求到达，Nginx 会处理第一个请求，剩余20个请求将放入队列，然后每隔100ms从队列中获取一个请求进行处理。若请求数大于21，将拒绝处理多余的请求，直接返回503.<br><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710753156756-49a1e806-3217-4c30-b066-aac4abebd2fd.png#averageHue=%23faf9f9&clientId=u5817dd03-6324-4&from=paste&height=352&id=u2b40df16&originHeight=635&originWidth=781&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=58342&status=done&style=none&taskId=u87e1aa93-245b-4674-8828-62b36eac0e8&title=&width=432.79998779296875" alt="image.png"><br>逻辑上叫漏桶，实现起来是FIFO队列，把得不到执行的请求暂时缓存起来。这样漏出的速度仍然是100ms一个请求，但并发而来，暂时得不到执行的请求，可以先缓存起来。只有当队列满了的时候，才会拒绝接受新请求。这样漏桶在限流的同时，也起到了削峰填谷的作用。在这样的配置下，如果有10次请求同时到达，它们会依次执行，每100ms执行1个。虽然得到执行了，但因为排队执行，延迟大大增加，在很多场景下仍然是不能接受的。<br>不过，单独使用 burst 参数并不实用。假设 burst&#x3D;50 ，rate依然为10r&#x2F;s，还是每100ms执行一个请求，排队中的50个请求虽然每100ms会处理一个，但第50个请求却需要等待 50 * 100ms即 5s，这么长的处理时间自然难以接受。<br>因此，burst 往往结合 nodelay 一起使用。nodelay 把开始执行请求的时间提前，以前是delay到从桶里漏出来才执行，现在不delay了，只要入桶就开始执行。<br>nodelay参数允许请求在排队的时候就立即被处理，也就是说只要请求能够进入burst队列中则立刻执行，不会等100ms取出一个执行，就会立即被后台worker处理</p><blockquote><p>请注意，这意味着burst设置了nodelay时，系统瞬间的QPS可能会超过rate设置的阈值。nodelay参数要跟burst一起使用才有作用。<br>假设burst&#x3D;50 nodelay</p></blockquote><p><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710753334572-28654b31-d1c7-4351-9234-f9afc643503a.png#averageHue=%23faf9f9&clientId=u5817dd03-6324-4&from=paste&height=357&id=u03e1e6cd&originHeight=633&originWidth=767&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=58132&status=done&style=none&taskId=u37043f2e-f8d4-4085-9ac8-2ee339f38fa&title=&width=432.60003662109375" alt="image.png"></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">   <span class="section">location</span> / &#123;</span><br><span class="line">      <span class="attribute">limit_req</span> zone=myRateLimit burst=<span class="number">20</span> nodelay;</span><br><span class="line">      <span class="attribute">proxy_pass</span> http://my_upstream;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>nodelay</strong> 针对的是 burst 参数，<code>burst=20 nodelay</code>表示这20个请求立马处理，不能延迟，相当于特事特办。不过，即使这20个突发请求立马处理结束，后续来了请求也不会立马处理。<code>burst=20</code> 相当于缓存队列中占了20个坑，即使请求被处理了，这20个位置这只能按 100ms一个来释放。这就达到了速率稳定，突然流量也能正常处理的效果。<br>各参数的意义如下：</p><ul><li>zone：指定引用limit_req_zone中哪一块共享内存，用于保存限流数据。</li><li>burst：表示允许超过限流值的突发请求数。当超出限流值的请求数小于burst值时，这些过量的请求进入队列等待，系统按照限流速率继续处理这部分请求；超过burst值的请求则会被拒绝。</li><li>nodelay：表示进入等待队列的请求优先处理，这样可以尽量避免请求处理超时。该参数必须配合burst值一起使用。<blockquote><p>加入了nodelay参数之后的限速算法，到底算是哪一个“桶”，是漏桶算法还是令牌桶算法？<br>当然还算是漏桶算法。<br>考虑一种情况，令牌桶算法的token未耗尽时会怎么做呢？由于它有一个请求队列，所以会把接下来的请求缓存下来，缓存多少受限于队列大小。但此时缓存这些请求还有意义吗？如果server已经过载，缓存队列越来越长，RT越来越高，即使过了很久请求被处理了，对用户来说也没什么价值了。所以当token不够用时，最明智的做法就是直接拒绝用户的请求，这就成了漏桶算法。</p></blockquote></li></ul><h4 id="限制连接数"><a href="#限制连接数" class="headerlink" title="限制连接数"></a>限制连接数</h4><p><a href="https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html">ngx_http_limit_conn_module</a> 提供了限制连接数的能力，利用 limit_conn_zone 和 limit_conn  两个指令即可。下面是 Nginx 官方例子：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">limit_conn_zone</span> <span class="variable">$binary_remote_addr</span> zone=perip:<span class="number">10m</span>;</span><br><span class="line"><span class="attribute">limit_conn_zone</span> <span class="variable">$server_name</span> zone=perserver:<span class="number">10m</span>;</span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">    <span class="attribute">limit_conn</span> perip <span class="number">10</span>;</span><br><span class="line">    <span class="attribute">limit_conn</span> perserver <span class="number">100</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>limit_conn perip 10</strong> 作用的key 是 <strong>$binary_remote_addr</strong>，表示限制单个IP同时最多能持有10个连接。<br><strong>limit_conn perserver 100</strong> 作用的key是 <strong>$server_name</strong>，表示虚拟主机(server) 同时能处理并发连接的总数。<br>需要注意的是：只有当 <strong>request header</strong> 被后端server处理后，这个连接才进行计数。</p><h2 id="Nginx高可用架构设计"><a href="#Nginx高可用架构设计" class="headerlink" title="Nginx高可用架构设计"></a>Nginx高可用架构设计</h2><p><img src="https://cdn.nlark.com/yuque/0/2024/png/32521102/1710754641526-43d0264e-2bab-47cb-8554-34a205826d83.png#averageHue=%23e8e5d1&clientId=u5817dd03-6324-4&from=paste&height=766&id=ua09e20d2&originHeight=958&originWidth=1398&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=617227&status=done&style=none&taskId=ua8a3f3b3-470c-454c-96e4-0518cb887b9&title=&width=1118.4" alt="image.png"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
            <tag> 常见场景 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis高级</title>
      <link href="/posts/db4d2069.html"/>
      <url>/posts/db4d2069.html</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-高级"><a href="#Redis-高级" class="headerlink" title="Redis 高级"></a>Redis 高级</h1><p>本章节是 “Redis初级” 的进阶版本，主要内容为 “AOF持久化”、“RDB持久化”、“使用docker安装redis” 和 “Redis集群搭建” 的内容。</p><h1 id="1-AOF持久化实践"><a href="#1-AOF持久化实践" class="headerlink" title="1.AOF持久化实践"></a>1.AOF持久化实践</h1><h2 id="1-1-修改配置文件"><a href="#1-1-修改配置文件" class="headerlink" title="1.1 修改配置文件"></a>1.1 修改配置文件</h2><p>修改 redis.conf 文件，在其中编写如下配置信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes # 启动AOF持久化机制</span><br><span class="line">appendfsync everysec # 设置了持久化的策略，即持久化的频率是——每秒</span><br><span class="line">dir ./ # 设置了持久化文件的保存路径</span><br></pre></td></tr></table></figure><p>这里没有通过 appendfilename 参数设置持久化文件的名字，所以会选用默认的 appendonly.aof 文件名</p><h2 id="2-1-重新启动-redis"><a href="#2-1-重新启动-redis" class="headerlink" title="2.1 重新启动 redis"></a>2.1 重新启动 redis</h2><p>检查 redis 是否是启动中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep redis</span><br></pre></td></tr></table></figure><p>关闭 redis</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a 123456 shutdown</span><br></pre></td></tr></table></figure><p>重启 redis</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到 redis.config 所在目录</span></span><br><span class="line">/opt/server/redis-6.2.7</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载配置文件启动</span></span><br><span class="line">redis-server redis.conf</span><br></pre></td></tr></table></figure><h2 id="3-1-操作-redis"><a href="#3-1-操作-redis" class="headerlink" title="3.1 操作 redis"></a>3.1 操作 redis</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set name zhangsan</span><br><span class="line">set age 22</span><br><span class="line">get name</span><br></pre></td></tr></table></figure><p>此时 AOF 持久化机制已经生效，每秒会同步持久化文件，而且之前也运行了若干写命令，所以可以观察 AOF 持久化文件里的内容。</p><p>查看当前目录下（允许 redis-server 所在目录）appendonly.aof 文件中的内容</p><p><img src="https://i0.hdslb.com/bfs/album/8a2582d8ab81e39127bd5d583ef70f4ef883db56.png" alt="image-20221124161730684"></p><p>第一条命令是 select 0，表示开启 0 号数据库，能看到第二条和第三条 set 命令，get name 命令是读命令，所以不会写入持久化文件</p><h2 id="4-1-模拟数据恢复"><a href="#4-1-模拟数据恢复" class="headerlink" title="4.1 模拟数据恢复"></a>4.1 模拟数据恢复</h2><p>flushall 命令能清空 Redis 的所有内存数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flushall</span><br></pre></td></tr></table></figure><p>注意 flushall 命令也会记录到 aof 文件中，打开 AOF 文件，删除最后一行的 flushall 命令，如果不删除，在进行数据恢复时还会运行这条命令，从而把数据清空</p><p>关闭 redis 服务，并重启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a 123456 shutdown</span><br><span class="line">redis-server redis.conf</span><br></pre></td></tr></table></figure><p>观察数据是否被还原</p><h1 id="2-RDB-持久化实践"><a href="#2-RDB-持久化实践" class="headerlink" title="2.RDB 持久化实践"></a>2.RDB 持久化实践</h1><h2 id="2-1-修改配置文件"><a href="#2-1-修改配置文件" class="headerlink" title="2.1 修改配置文件"></a>2.1 修改配置文件</h2><p>在 Redis 的 redis.conf 配置文件里，可以通过 save 参数配置生成 RDB 快照的条件，具体代码如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 600 1 # 表示当在600秒内有1个或1个以上的键被修改时就会生成快照</span><br><span class="line">save 300 100# ...300秒...大于或等于100个.....</span><br><span class="line">save 60 1000# ...60秒...大于或等于1000个.....</span><br></pre></td></tr></table></figure><p>注意，这三个条件是”或“的关系，即只要有一个条件被满足，就会生成快照。从中能看出，RDB 持久化文件只是当条件满足后生成快照，所以无法即时保存当前状态的内存数据。也就是说，通过RDB恢复数据时，会丢失上次生成快照后更新的数据。</p><p>同时，在 redis.conf 里加上如下两条描述快照文件名的配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dbfilename redis.rdb</span><br></pre></td></tr></table></figure><h2 id="2-2-重新启动-redis"><a href="#2-2-重新启动-redis" class="headerlink" title="2.2 重新启动 redis"></a>2.2 重新启动 redis</h2><p>检查 redis 是否启动中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep redis</span><br></pre></td></tr></table></figure><p>关闭 redis</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a 123456 shutdown</span><br></pre></td></tr></table></figure><p>重启 redis</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到 redis.config 所在目录</span></span><br><span class="line">/opt/server/redis-6.2.7</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载配置文件启动</span></span><br><span class="line">redis-server redis.conf</span><br></pre></td></tr></table></figure><h2 id="2-3-操作redis"><a href="#2-3-操作redis" class="headerlink" title="2.3 操作redis"></a>2.3 操作redis</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set name lisi</span><br></pre></td></tr></table></figure><p>此时满足”600秒里有一个或一个以上键被修改“这个条件，所以能看到 RDB 持久化文件 redis.rdb，不过 RDB 持久化文件是二进制格式，所以用记事本打开后看到的是乱码。</p><h2 id="2-4-用快照文件恢复数据"><a href="#2-4-用快照文件恢复数据" class="headerlink" title="2.4 用快照文件恢复数据"></a>2.4 用快照文件恢复数据</h2><p>和 AOF 持久化方式一样，通过 RDB 的快照文件可以恢复数据，如果 redis 数据出现了丢失，在去启动时会根据快照文件恢复数据</p><h1 id="3-使用-docker-安装-redis"><a href="#3-使用-docker-安装-redis" class="headerlink" title="3.使用 docker 安装 redis"></a>3.使用 docker 安装 redis</h1><p>用 docker pull 下载最新版的 Redis 镜像，也可以用 ”docker pull redis:标签“命令下载指定版本的 Redis，如果不指定，就会用默认的标签 latest 去下载最新版本的 Redis 镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull redis</span><br></pre></td></tr></table></figure><p>docker images，表示已经成功下载了最新版本的 Redis 镜像</p><p><img src="https://i0.hdslb.com/bfs/album/939d1e3be9866360d82b04111f971c49027e2263.png" alt="image-20221124193702394"></p><h2 id="3-1-运行-Redis-容器"><a href="#3-1-运行-Redis-容器" class="headerlink" title="3.1 运行 Redis 容器"></a>3.1 运行 Redis 容器</h2><p>随后可以用如下的 run 命令来运行 Redis 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-test1 -p 6379:6379 redis:5.0.14</span><br></pre></td></tr></table></figure><p>这里的 <code>-it</code> 表示在终端交互式操作，d 表示在后台运行；通过 <code>--name</code> 指定该容器的名字；通过 <code>-p</code> 参数指定容器的 6379 端口映射到宿主机（即运行 Docker 的机器）6379 端口，这样在容器外部就能以宿主机 <code>ip:6379</code> 的方式访问 Redis 服务；最后的 <code>redis:5.0.14</code> 参数指定根据该镜像启动容器</p><p>运行完上述 <code>run 命令</code>后在执行 <code>docker ps</code> 命令：</p><p><img src="https://i0.hdslb.com/bfs/album/2dcea5f9db4d5731b87d50c541254d9883a87697.png" alt="image-20221124194538385"></p><p>从中可以看到，名为 redis-test1的容器处于 Up状态，并且是通过 6379 端口对外提供服务的。</p><h3 id="查看启动日志"><a href="#查看启动日志" class="headerlink" title="查看启动日志"></a>查看启动日志</h3><p>如果直接在 Linux 等环境上启动 Redis 服务器，就能直接看到启动后的效果。这里由于通过 Docker 容器启动 Redis 服务，因此在用 <code>docker run</code> 命令启动 Redis 容器后，可以通过如下的 <code>docker log</code> 命令来观察启动的效果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs redis-test1</span><br></pre></td></tr></table></figure><p>上述 docker logs 命令用来输出容器启动时的日志，redis-test1 则表示待查看日志的容器名。如果 Docker 容器中的Redis 正确启动，就能看到如图效果：</p><p><img src="https://i0.hdslb.com/bfs/album/cb0429542b923a9198b03c1f988fd6c00525c9e3.png" alt="image-20221124200713567"></p><h2 id="3-2-进入Redis容器"><a href="#3-2-进入Redis容器" class="headerlink" title="3.2 进入Redis容器"></a>3.2 进入Redis容器</h2><p>通过 run 命令能在后台启动 Redis 容器，此时可以通过如下的 <code>exec</code> 命令进入 Redis 容器，进而执行 Redis 的相关操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-test1 /bin/bash</span><br></pre></td></tr></table></figure><p><code>docker exec</code> 表示在运行的容器中执行命令，其中 redis-test1 参数表示在哪个容器里执行命令，-it 表示以终端交互的方式执行命令，<code>/bin/bash</code> 表示需要指定的命令</p><p>执行上述 exec 命令后，就能看到如图所示的效果，说明已经进入了名为 redis-test1 的容器</p><p><img src="https://i0.hdslb.com/bfs/album/2294fb2d1146abf2bc377bdc979ee2dc9f392347.png" alt="image-20221124201651774"></p><p>可以通过输入 <code>redis-cli</code> 命令连接容器里的 Redis 服务器，随后可以通过 <code>set val 1</code> 命令创建一个值为1的val变量，创建后再通过 <code>get val</code> 来获取val变量的值：</p><p><img src="https://i0.hdslb.com/bfs/album/c39753bcfb2816827af8dac922aba93dc21993d7.png" alt="image-20221124202116628"></p><p>当然也可以通过其他客户端工具访问。只要能成功地运行 Redis 相关命令并看到对应地结果，就说明基于 Docker 的 Redis 成功地安装到本机里了</p><h2 id="3-3-退出-Redis-容器"><a href="#3-3-退出-Redis-容器" class="headerlink" title="3.3 退出 Redis 容器"></a>3.3 退出 Redis 容器</h2><p>随后如果想退到Windows命令行，就需要连续两次输入exit，其中第一个exit命令能退出用 redis-cli 进入地 redis 运行窗口，第二个exit命令能退出因 docker exec命令而进入地 redis 容器。</p><p>可以通过 docker stop redis-test1命令停止该容器，其实 redis-test1 是待停止的容器名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop redis-test1</span><br></pre></td></tr></table></figure><p>要再次启动该容器，可以使用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker start redis-test1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">或</span></span><br><span class="line">docker restart redis-test1</span><br></pre></td></tr></table></figure><p>这两个命令的差别是，<code>docker start **</code> 会挂载容器所关联的文件系统，而 <code>docker restart **</code> 不会</p><h2 id="3-4-启动时加载配置文件"><a href="#3-4-启动时加载配置文件" class="headerlink" title="3.4 启动时加载配置文件"></a>3.4 启动时加载配置文件</h2><p>通过 docker 命令，用 Redis 的镜像创建容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis2 -v /opt/server/redis-6.2.7/redis.conf:/redisConfig/redis.conf -p 6379:6379 redis:5.0.14 redis-server /redisConfig/redis.conf</span><br></pre></td></tr></table></figure><p>通过 <code>--name</code> 的方式指定该容器的名字为 <code>redis2</code> ，用 <code>-v</code> 指定本机和 Docker 虚拟机内目录和文件的映射关系，具体是把 &#x2F;opt&#x2F;server&#x2F;redis-6.2.7&#x2F;redis.conf 映射成 Docker 虚拟机里的 redisConfig&#x2F;redis.conf 文件，用 <code>-p</code> 参数来指定 Docker 虚拟机的 6379 端口映射到本机的 6379 端口上，以 redis；latest 的方式指定本容器的镜像为指定版本的 redis 镜像</p><p>再用 redis-server &#x2F;redisConfig&#x2F;redis.conf 的方式指定启动 redisWithConfig 镜像，即用 redis-server 命令启动 Redis 服务器时需要装载对应的 redis.conf 文件</p><p><strong>注意事项：</strong></p><ul><li>redis.conf 的 daemonize表示是否守护进行执行</li><li>docker run 命令里有一个参数 <code>-d</code> ，这个参数也是守护进程执行</li><li>为了防止冲突要修改 redis.conf 配置文件，把 daemonize 修改为 no</li></ul><h1 id="4-Redis集群"><a href="#4-Redis集群" class="headerlink" title="4. Redis集群"></a>4. Redis集群</h1><h2 id="4-1-主从复制模式集群"><a href="#4-1-主从复制模式集群" class="headerlink" title="4.1 主从复制模式集群"></a>4.1 主从复制模式集群</h2><h3 id="1-用命令搭建主从集群"><a href="#1-用命令搭建主从集群" class="headerlink" title="1 用命令搭建主从集群"></a>1 用命令搭建主从集群</h3><p>这里将用Docker容器来搭建一主二从模式的集群，在配置主从关系时，需要在从节点上使用slaveof命令，具体的步骤如下：</p><p>打开一个命令窗口，在其中运行如下命令创建一个名为redis-master的Redis容器。注意，它的端口是6379。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-master -p 6379:6379 redis:6.2.7</span><br></pre></td></tr></table></figure><p>新开一个命令窗口，在其中运行如下命令创建一个名为redis-slave1的容器。注意，它的端口是6380。这里是在一台电脑上运行，所以用端口号来区别<strong>一台主Redis容器</strong>和另外<strong>两台从Redis容器</strong>。在真实项目里，多台Redis会部署在不同的服务器上，所以可以都用6379端口。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-slave1 -p 6380:6380 redis:6.2.7</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/album/00be6933403555eddec362b12467f71cc1ea9f87.png" alt="image-20221124214604305"></p><p>回到包含 redis-master 容器的命令窗口，在其中运行 docker inspect redis-master命令，查看 redis-master 容器的信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect redis-master | grep IPAddress</span><br></pre></td></tr></table></figure><p>在其中能通过 IPAddress 项看到该容器的 IP 地址，这里是 <code>172.17.0.2</code> 。在真实项目里，Redis 服务器所在的 IP地址 是固定的，而通过Docker 容器启动的 Redis 服务器的 IP地址 是动态的，所以这里要用上述命令来获取IP地址。</p><p><img src="https://i0.hdslb.com/bfs/album/9973d95ca3f00343a51321aa5c9f26d5039184fc.png" alt="image-20221124214634829"></p><p>在 redis-master 容器的命令窗口里，运行 docker exec -it redis-master &#x2F;bin&#x2F;bash 命令，进入命令行窗口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-master /bin/bash</span><br></pre></td></tr></table></figure><p>在其中用 <code>redis-cli</code> 命令进入 Redis 客户端命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli</span><br></pre></td></tr></table></figure><p>通过 <code>info replication</code> 命令查看当前的主从模式状态，能看到如下所示的部分结果。&#x3D;&#x3D;默认为主服务器&#x3D;&#x3D;</p><p><img src="https://i0.hdslb.com/bfs/album/5f5cc7f93e17939a9a197eac792b5af9ff1f23fd.png" alt="image-20221124214824360"></p><p>由于此时还没有通过命令行设置主从模式，因此输出结果里依然能看到当前服务器是”主服务器“，同时没有携带从服务器</p><p>在 redis-slave1容器的命令窗口里运行如下的 <code>slaveof</code> 命令，指定当前 Redis 服务器为从服务器。该命令的格式是 <code>slaveof IP地址端口号</code>，这里指向 <code>172.17.0.2:6379</code> 所在的主服务器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slaveof 172.17.0.2 6379</span><br></pre></td></tr></table></figure><p>运行完该命令后，在 redis-slave1 客户端里再次运行 <code>info replication</code>，会看到如下所示的部分结果</p><p><img src="https://i0.hdslb.com/bfs/album/ef2ebb8fe25e3658c77e3a896a819d8b6f8aa775.png" alt="image-20221124215521366"></p><p>回到 redis-master 客户端里运行 <code>info replication</code>，会看到如下部分结果</p><p><img src="https://i0.hdslb.com/bfs/album/1ad6be0e84db40d08df8c7d2fc719f2d6dbe8fb2.png" alt="image-20221124215845993"></p><p>打开一个新的命令窗口，在其中运行如下命令，开启一个新的名为 redis-slave2 的Redis 容器。注意，它的端口是 6381。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-slave2 -p 6381:6381 redis:6.2.7</span><br></pre></td></tr></table></figure><p>随后按照 &#x3D;&#x3D;redis-slave1&#x3D;&#x3D; 的从机配置方式配置 redis-slave2。</p><p><img src="https://i0.hdslb.com/bfs/album/21b59cffceea8f008862bb6e5a4e3b3148ed661d.png" alt="image-20221124220516961"></p><p>连接完成后，回到 redis-master 容器所在的命令行窗口，运行 <code>info replication</code> 命令，此时能看到如下的部分输出，从第4行的输出里能看到当前的主服务器连接着两台从服务器</p><p><img src="https://i0.hdslb.com/bfs/album/238c690dc895f15307eb25e667dc44a49124a30e.png" alt="image-20221124220752010"></p><p>至此，配置完成一主二从模式的主从模式。</p><p>此时，到两太从服务器里运行 <code>get name</code> 命令，返回是空；在 redis-master容器所在的命令窗口运行 <code>set name Zhangsan</code> 后，再到两台从服务器里运行 <code>get name</code> 命令，就能看到返回值。</p><p><img src="https://i0.hdslb.com/bfs/album/3847e844acc53869cac4b1926079bab1f7bbd00e.png" alt="image-20221124221153240"></p><p><img src="https://i0.hdslb.com/bfs/album/a0a280daa8b10e5cb4d3f36775649ac2f6651363.png" alt="image-20221124221214023"></p><p>&#x3D;&#x3D;说明主从模式配置成功，主服务器里的数据会自动同步到各从服务器上&#x3D;&#x3D;</p><h3 id="2-通过配置搭建主从集群"><a href="#2-通过配置搭建主从集群" class="headerlink" title="2 通过配置搭建主从集群"></a>2 通过配置搭建主从集群</h3><p>在项目里除了可以用 <code>slaveof</code> 命令搭建主从模式的集群外，还可以用配置参数的方式来搭建，具体的步骤如下：</p><p>搭建主服务器 redis-master 的命令不变，并且还是用 6379 端口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-master -p 6379:6379 redis:6.2.7</span><br></pre></td></tr></table></figure><p>用 <code>docker inspect redis-master</code> 命令确认该 Redis 服务武器所在容器的 IP地址仍然是 <code>172.17.0.2</code></p><p>在 <code>/opt/server</code> 下编写配置文件 <code>redisSlave1.conf</code> ，并在其中编写如下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">port 6380# 设置该Redis的端口为6380</span><br><span class="line">slaveof 172.17.0.2 6379# 设置该Redis服务器为”从模式“，并连接到 redis-master 所在的主服务器上</span><br></pre></td></tr></table></figure><p>在新的命令窗口里运行如下的命令，创建名为 redis-slave1 的Redis服务器。该服务器的工作端口是 6380，并且用 redis-server 后的参数指定在启动 Redis 服务器时加载 redisSlave1.conf 配置文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-slave1 -v /opt/server/redisSlave1.conf:/redisConfig/redisSlave1.conf -p 6380:6380 redis:6.2.7 redis-server /redisConfig/redisSlave1.conf</span><br></pre></td></tr></table></figure><p>随后通过 <code>docker exec -it redis-slave1 /bin/bash</code> 命令进入到该容器的命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-slave1 /bin/bash</span><br></pre></td></tr></table></figure><p>由于 Redis 工作端口已经变成 6380（配置文件中指定了端口），所以需要通过 <code>redis-cli -h 127.0.0.1 -p 6380</code> 命令进入Redis客户端。在其中运行 <code>info replication</code> 命令</p><p><img src="https://i0.hdslb.com/bfs/album/89f6688eac2d718f7de63b9c4cfa5b2d281c7a99.png" alt="image-20221124224934063"></p><p>以同样的方式创建 redis-slave2，将端口绑定到 6381 即可</p><p><img src="https://i0.hdslb.com/bfs/album/295f7c00f0cfcab0bdd828f1cec1638e7f106ede.png" alt="image-20221124225709626"></p><p><img src="https://i0.hdslb.com/bfs/album/4c1a2d4b6c0257a8d8d62268b2d174ca96980a60.png" alt="image-20221124225806586"></p><h3 id="3-配置读写分离效果"><a href="#3-配置读写分离效果" class="headerlink" title="3 配置读写分离效果"></a>3 配置读写分离效果</h3><p>在上文里配置的 redis-slave1 和 redis-slave2 这两台从服务器里运行 <code>info replication</code> 命令，还能看到  ”slave_read_only:1“ 这项配置，说明从服务器默认是”只读“的。</p><p>在从机的 redis 客户端命令行里输入 <code>set val 1</code> ，会提示错误，从而进一步验证该 Redis 服务器的 ”只读“属性。</p><p><img src="https://i0.hdslb.com/bfs/album/554d45b43462f426d9035fe76ac606e7d023e4cc.png" alt="image-20221124230324390"></p><p>对于 Redis 从服务器而言，建议采用默认的”只读“配置，因为在项目里一般不会向作为数据同步目的地的”从服务器“上写数据。如果业务上确实需要，可以通过如下步骤设置”可读可写“的效果</p><p>在上文提到的 redisSlave2.conf 配置文件里再加入一行 ”slave-read-only no“的配置，指定该服务器可读可写。</p><p>如果上文提到的 redis-slave2 容器还处于活动状态，则需要先用 <code>docker stop redis-slave2</code> 停用该容器，再用 <code>docker rm redis-slave2</code> 命令删除该容器，之后可以用如下命令再次创建 redis-slave2 容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-slave2 -v /opt/server/redisSlave2.conf:/redisConfig/redisSlave2.conf -p 6381:6381 redis:6.2.7 redis-server /redisConfig/redisSlave2.conf</span><br></pre></td></tr></table></figure><h3 id="4-用心跳机制提高主从复制的可靠性"><a href="#4-用心跳机制提高主从复制的可靠性" class="headerlink" title="4 用心跳机制提高主从复制的可靠性"></a>4 用心跳机制提高主从复制的可靠性</h3><p>在Redis主从复制模式里，如果主从服务器之间有数据同步的情况，那么从服务器会默认以一秒一次的频率向主服务器发送<code>REPLCONFACK命令</code>，依次来确保两者间连接通畅。这种定时交互命令确保连接的机制就叫”心跳”机制。</p><p>在上文开启的redis-master这个主服务器的命令行里，运行info replication命令，就能看到它从属服务器的“心跳””状况。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info replication</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/album/55a21380b5cf648c0408517d126eeff1590f0774.png" alt="image-20221124231213931"></p><p>通过 lag 表示该从属服务器发送 REPLCONFACK ACK 命令实践，这里均是1秒，表示两台从服务器和主服务器的连接均属通畅。</p><p>这里大家可以想象一下，如果从服务器宕机，那么主从复制就没有意义了。对此，可以通过如下的步骤来关联心跳机制和主动复制的动作。</p><p>在 <code>/opt/server</code> 下新建 redisMaster.conf 文件，在其中编写如下的代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">min-slaves-to-write 2# 表示实现主从复制的从服务器个数最少是2台</span><br><span class="line">min-slaves-max-lag 15# 表示如果第1行参数指定的从服务器个数（这里是2台）的心跳延迟时间(lag值)大于15s，就不执行主从复制</span><br></pre></td></tr></table></figure><p>这两个条件是”或者“关系，即只要出现从服务器个数小于2，或者2太从服务器的心跳延迟大于15s，主服务器即停止主从复制的操作。</p><p>需要重新启动主服务器容器，加载配置文件</p><p>在上文开启的redis-master主服务器的命令行里，运行info replication命令，能看到表示复制数据偏移量的master_repl_offset数据这里的数据是1614，表示主服务器向从服务器发送数据的字节数。</p><p>同样，到redis-slave1从服务器的命令行里也能通过info replication查看该偏移量。</p><p>在从服务器里，该数据表示从主服务器中接收到的数据字节数，如果主从服务器中两者的数据一致，就说明主从服务器间的数据是同步的。</p><p>如果出现Redis问题，可以通过master_repl_offset数值来检查同步数据是否正确，由此再进一步排查问题。</p><h2 id="4-2-哨兵模式集群"><a href="#4-2-哨兵模式集群" class="headerlink" title="4.2 哨兵模式集群"></a>4.2 哨兵模式集群</h2><h3 id="1-搭建哨兵模式集群"><a href="#1-搭建哨兵模式集群" class="headerlink" title="1 搭建哨兵模式集群"></a>1 搭建哨兵模式集群</h3><p>通过如下的步骤，大家可以用 Docker 容器搭建基于哨兵的集群，由此可以感受到各节点的作用以及整个集群的工作方式。</p><p>首先按照之前 （&#x3D;&#x3D;添加连接&#x3D;&#x3D;）的方法搭建一个一主二从的 redis 集群，其中 redis-master 是主服务器，redis-slave1 和 redis-slave2 是从服务器。</p><p>在 <code>/opt/server</code> 目录里创建 sentine1.conf 配置文件，该配置文件会在启动哨兵节点时被读取，代码如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">port 16379 # 指定哨兵节点的工作端口</span><br><span class="line">sentinel monitor master 172.17.0.2 6379 2 </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定监控对象。master是哨兵结点为所监控服务器指定的名字，172.17.0.2和6379分别表示 redis-master 这台主服务器的ip和端口号，2表示至少需要有2台哨兵节点认可才能认定该主服务器失效。</span></span><br><span class="line">logfile &quot;sentinel1.log&quot; # 指定该哨兵节点的日志文件名</span><br></pre></td></tr></table></figure><p> 完成编写上述配置文件后，新开一个命令窗口，在其中运行如下的命令，新启一个名为 redis-sentine1 的 Docker 容器，并在其中启动哨兵（sentinel）节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod -R 777 /opt/server/</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-sentinel1 -v /opt/server:/redisConfig:z -p 16379:16379 redis:6.2.7 redis-server /redisConfig/sentinel1.conf --sentinel</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/album/0b55fe8fa2ce8ef0f236fe267468caf571653b96.png" alt="image-20221125093119744"></p><p>通过上述命令启动一个哨兵节点后，可以通过 <code>docker exec -it redis-sentinel1 /bin/bash</code> 命令进入Docker容器里的命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-sentinel1 /bin/bash</span><br></pre></td></tr></table></figure><p>然后通过下述命令进入 Redis 客户端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 16379</span><br></pre></td></tr></table></figure><p>在 Redis 客户端里，查看哨兵节点的信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info sentinel</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/album/418ff5b240dece139c44f4da52bbb94500909995.png" alt="image-20221125094849062"></p><p>该哨兵节点监控的主服务器状态（status）是ok，slaves数量是2，即该主服务器有2个从服务器，这个之前的配置情况是一致的。</p><p>创建 sentinel2.conf 配置文件，其中的代码如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">port 16380</span><br><span class="line">sentinel monitor master 172.17.0.2 6379 2</span><br><span class="line">logfile &quot;sentinel2.log&quot;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 /opt/server/sentinel2.conf</span><br></pre></td></tr></table></figure><p>该配置文件和哨兵节点 redis-sentinel1所用到的很相似，只不过是把端口改为 16380，同时更改了日志文件名</p><p>随后开启一个命令窗口，在其中创建一个哨兵节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-sentinel2 -v /opt/server:/redisConfig:z -p 16380:16380 redis:6.2.7 redis-server /redisConfig/sentinel2.conf --sentinel</span><br></pre></td></tr></table></figure><p>随后进入该哨兵节点的命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-sentinel2 /bin/bash</span><br></pre></td></tr></table></figure><p>进入redis 客户端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 16380</span><br></pre></td></tr></table></figure><p>在 redis 客户端里通过命令查看哨兵节点的状态信息，能看到如下结果</p><p><img src="https://i0.hdslb.com/bfs/album/79f94684b4e37755d64c48e91011972065aab11a.png" alt="image-20221125095844340"></p><p>该哨兵节点正在监控 172.17.0.2:6379 指向的主服务器，再观察 sentinels 的值是2，表示 172.17.0.2:6379 指向的服务器（redis-master主服务器）被两台哨兵节点监控。</p><p>至此，完成了哨兵节点监控”一主二从“的集群，该集群的架构如图所示。在实际项目里，可以通过配置让哨兵节点监控多个集群。</p><img src="https://i0.hdslb.com/bfs/album/b10f25b0295759d0233463d603123a703d5a71ee.png" alt="image-20221125100606552" style="zoom:67%;" /><h3 id="2-哨兵节点的常用配置"><a href="#2-哨兵节点的常用配置" class="headerlink" title="2 哨兵节点的常用配置"></a>2 哨兵节点的常用配置</h3><p>在上文里，通过 <code>sentinel monitor master 172.17.0.2 6379 2</code> 配置参数来设置该节点所监控的主机，此外还可以通过 <code>sentinel down-after-milliseconds</code> 参数来指定判断下线时间的阈值，下面给出一个具体的用法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel down-after-milliseconds master 60000</span><br></pre></td></tr></table></figure><p>其中，master 表示该哨兵节点监控的服务器名，需要和sentinel monitor 配置项里指定的服务器名保持一致，而60000表示时间，单位是毫秒。也就是说，如果在60秒里该哨兵节点没有收到master服务器的正确响应，就会认为该服务器已经下线失效</p><p>只有当2个哨兵节点（ <code>sentinel monitor master 172.17.0.2 6379 2</code> 中2就是这个作用）都通过”sentinel down-after-milliseconds”判断该服务器失效时才会认定该服务器失效，从而启动故障恢复机制。</p><p>此外，还可以通过如下配置来设置”故障恢复的时效“，该时效参数的单位是 毫秒，这里的含义是，在进行故障恢复时，如果在180秒里还没有完成主从服务器的切换，就会认定本次恢复动作失败。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel failover-timeout master 180000</span><br></pre></td></tr></table></figure><h3 id="3-哨兵模式下的故障自动恢复"><a href="#3-哨兵模式下的故障自动恢复" class="headerlink" title="3 哨兵模式下的故障自动恢复"></a>3 哨兵模式下的故障自动恢复</h3><p>通过上文的配置，能实现用哨兵节点监控主从复制模式里主服务器的效果。</p><p>这里将演示主服务器失效后故障自动恢复的效果：</p><p>到 redis-master 这个 Docker 容器所在的命令窗口里，用 exit 命令退出 Docker 容器，并停止该容器里的 Redis 服务器，以此来模拟主服务器失效的效果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop redis-master</span><br></pre></td></tr></table></figure><img src="https://i0.hdslb.com/bfs/album/1194ef0f941058684ccc451926001e84f933387f.png" alt="image-20221125112303803" style="zoom:80%;" /><p>在 redis-sentinel1 这个哨兵节点所在的命令行窗口，通过 <code>info sentinel</code> 命令观察该哨兵节点所监控的主从集群状态，能看到如下的效果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info sentinel</span><br></pre></td></tr></table></figure><p>因为哨兵节点有默认的等待时间，所以需要等待一段时间</p><img src="https://i0.hdslb.com/bfs/album/8f6a69221e950e2f2551f3f74df0a62cf18e45f4.png" alt="image-20221125112406484" style="zoom:80%;" /><p>切换到 <code>172.17.0.3:6380</code> （redis-slave1）对应的命令窗体，运行命令，能看到如下部分结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info replication</span><br></pre></td></tr></table></figure><img src="https://i0.hdslb.com/bfs/album/6e72560a33706f15e7a1c07d491833b498394d56.png" alt="image-20221125113312594" style="zoom:80%;" /><h3 id="4-通过日志观察故障恢复流程"><a href="#4-通过日志观察故障恢复流程" class="headerlink" title="4 通过日志观察故障恢复流程"></a>4 通过日志观察故障恢复流程</h3><p>由于在启动redis-sentinel1和redis-sentinel2节点时指定了日志的路径和位置，这里可以在对应的Docker容器里通过日志观察具体的故障恢复流程。</p><p>日志里有sdown的字样，sdown的含义是“主观下线”，与之对应的有表示客观下线的odown。</p><p>当本哨兵节点发现所监控的master服务器下线后，会先把它标记为”主观下线”，当多个哨兵节点（根据设置，这里需要是2个）都判断该服务器下线后，把该服务器标志成“客观下线”。</p><p>当检测到客观下线后，启动故障恢复（failover)流程，完成故障恢复后，会如第19行日志所示，切换主服务器，切换完成后，加载从服务器。至此，完成了故障自动恢复的流程。</p><p>只能由一个哨兵节点完成故障自动恢复的动作，因此如果有多个哨兵节点同时监控到主服务器失效，那么最终只能有一个哨兵节点通过竞争得到故障恢复的权力。</p><img src="https://i0.hdslb.com/bfs/album/be3fa9e4e81ee7e2c9f82ba1a318d163bb883ae6.png" alt="image-20221125113721883" style="zoom:80%;" /><h3 id="5-故障节点恢复后的表现"><a href="#5-故障节点恢复后的表现" class="headerlink" title="5 故障节点恢复后的表现"></a>5 故障节点恢复后的表现</h3><p>在 redis-master 所在的窗口重新启动redis服务器，以此来模拟该服务器排除故障后的效果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker start redis-master</span><br></pre></td></tr></table></figure><p>运行完命令后，再到 redis-slave1 所在的命令窗口里运行 <code>info replication</code> 命令，就能看到如下的输出，从输出里能确认故障恢复后的 redis-master 服务器会自动以 ”从服务器”的身份接入</p><img src="https://i0.hdslb.com/bfs/album/16ca665c22b6441d922a004ea93d43c3051d9c9f.png" alt="image-20221125114122264" style="zoom:80%;" /><p>哨兵节点不仅能自动恢复故障，而且当故障节点恢复后会自动把她重新加入到集群中，而无须人工干预。也就是说，与简单的“主从复制模式集群”相比，基于哨兵模式的集群能很好地提升系统地可靠性。</p><h2 id="4-3-cluster集群"><a href="#4-3-cluster集群" class="headerlink" title="4.3 cluster集群"></a>4.3 cluster集群</h2><h3 id="1-搭建cluster集群"><a href="#1-搭建cluster集群" class="headerlink" title="1 搭建cluster集群"></a>1 搭建cluster集群</h3><p>这里将通过如下步骤搭建 “三主三从” 的 cluster集群，由此大家能进一步理解 cluster集群。其他类型的 cluster集群，比如包含 4个主节点，或者每个主节点里再带2个从节点，可以照此步骤搭建。</p><p>在 <code>/opt/server</code> 目录里，新建名为 <code>cluster-m1.conf</code> 的配置文件，该配置文件用于配置 cluster 集群中的一个主节点，具体配置文件内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 6379 # 指定该redis服务器的端口为6379</span><br><span class="line">dir /redisConfig # 节点的日志路径</span><br><span class="line">logfile cluster-m1.log  # 节点的日志文件名</span><br><span class="line">cluster-enabled yes # 开启cluster集群模式，并把该节点加入集群</span><br><span class="line">cluster-config-file nodes-6379.conf  # 设置了该节点cluster集群相关的配置文件，该文件会自动生成</span><br></pre></td></tr></table></figure><p>依照上述配置文件，为第二个主节点创建名为 <code>cluster-m2.conf</code> 的配置文件，具体配置文件内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 6380</span><br><span class="line">dir /redisConfig</span><br><span class="line">logfile cluster-m2.log</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes-6380.conf</span><br></pre></td></tr></table></figure><p>以同样的方式配置 <code>cluster-m3.conf</code> ，将 port 设为 6381</p><img src="https://i0.hdslb.com/bfs/album/8555a1d14c58f3404140b296dff0ba3fd9c6b5dd.png" alt="image-20221125120921274" style="zoom: 80%;" /><p>然后创建 <code>cluster-s1.conf</code> 配置文件，用以配置第一个从节点，在其中编写如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 16379</span><br><span class="line">dir /redisConfig</span><br><span class="line">logfile cluster-s1.log</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes-16379.conf</span><br></pre></td></tr></table></figure><p>在配置文件里并没有设置主从关系，主从关系将在后续的步骤里设置。</p><p>根据 <code>cluster-s1.conf</code> 配置文件，再分别创建 <code>cluster-s2.conf</code> 、<code>cluster-s3.conf</code> ，对应端口分别为 16380、16381</p><img src="https://i0.hdslb.com/bfs/album/4249c37c620759947f87e8793632625fdb4d4491.png" alt="image-20221125121313067" style="zoom: 80%;" /><p>在完成编写上述配置文件的基础上，打开一个命令窗口，在其中运行如下的docker命令。创建名为 redis-m1 的docker容器，并在其中通过 redis-server 命令启动容器中的 redis 服务器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-m1 -v /opt/server:/redisConfig -p 6379:6379 redis:6.2.7 redis-server /redisConfig/cluster-m1.conf</span><br></pre></td></tr></table></figure><p>由于在通过 redis-server 命令启动 redis 服务器时传入了 cluster-m1.conf 配置文件，因此该容器里的 redis 会自动加入cluster集群，当然现在集群中只有者一个节点。</p><p>由于在 cluster-m1.conf 配置文件里指定了 cluster集群相关的配置文件是 node-6379.conf，因此在启动时会自动生成该文件，此时在与容器里 &#x2F;redisConfig 映射的 &#x2F;opt&#x2F;server 目录中就能看到生成的 node-6379.conf 文件</p><img src="https://i0.hdslb.com/bfs/album/9e36fddb8cacfc11b4a7135926b13f25297ff207.png" alt="image-20221125122146050" style="zoom:80%;" /><p>随后开启2个新的窗口，分别启动cluster集群中的第二个和第三个节点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-m2 -v /opt/server:/redisConfig -p 6380:6380 redis:6.2.7 redis-server /redisConfig/cluster-m2.conf</span><br><span class="line"></span><br><span class="line">docker run -itd --name redis-m3 -v /opt/server:/redisConfig -p 6381:6381 redis:6.2.7 redis-server /redisConfig/cluster-m3.conf</span><br></pre></td></tr></table></figure><p>以此类推，再新建3个命令窗口，在这3个命令窗口分别运行 docker run 命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-s1 -v /opt/server:/redisConfig -p 16379:16379 redis:6.2.7 redis-server /redisConfig/cluster-s1.conf</span><br><span class="line"></span><br><span class="line">docker run -itd --name redis-s2 -v /opt/server:/redisConfig -p 16380:16380 redis:6.2.7 redis-server /redisConfig/cluster-s2.conf</span><br><span class="line"></span><br><span class="line">docker run -itd --name redis-s3 -v /opt/server:/redisConfig -p 16381:16381 redis:6.2.7 redis-server /redisConfig/cluster-s3.conf</span><br></pre></td></tr></table></figure><p>运行完上述命令后，可以在任意一个开启着的命令窗口运行 <code>docker ps</code> ，确认上述 Redis 服务均已启动</p><img src="https://i0.hdslb.com/bfs/album/f23006c7d306ee44eaa892ae4615c8593b214d3c.png" alt="image-20221125122824760" style="zoom:80%;" /><p>由于这里是在一台主机上通过不同的Docker实例来启动多个Redis服务，因此用不同的端口号来区分每个Redis服务。在真实项目里，不同的Redis服务一般是安装在不同服务器上的，所以可以用IP地址来区分不同的Redis服务，而它们所用的端口可以都是6379。</p><p>此时打开描述redis-m1节点集群连接配置的nodes-6379.conf文件，就会看到如下的内容：</p><img src="https://i0.hdslb.com/bfs/album/e5c8642a2bd3e225601df982cb889e3e694da919.png" alt="image-20221125123048446" style="zoom:80%;" /><p>从第1行的输出里能看到该节点属于master (主)节点，它只连接到myself自身，没有同其他Redis节点关联。观察nodes-6380.conf等配置文件，也会发现当前这些节点均没有关联其他节点，在后继的步骤里，将用 <code>meet命令</code> 关联各节点。</p><p>先通过 <code>docker inspect redis-m1</code> 等命令查看上述各节点所在的IP地址，这其实也是诸多Redis服务器的IP地址。大家在自己电脑上实践的时候用dokcer run命令所创建的Redis服务器IP地址未必和本教程一致，如果有不一致的，就需要对应地修改下文给出的meet命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect redis-m1 | grep IPAddress</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">节点名称</th><th align="center">IP地址</th><th align="center">端口</th></tr></thead><tbody><tr><td align="center">redis-m1</td><td align="center">172.17.0.2</td><td align="center">6379</td></tr><tr><td align="center">redis-m2</td><td align="center">172.17.0.3</td><td align="center">6380</td></tr><tr><td align="center">redis-m3</td><td align="center">172.17.0.4</td><td align="center">6381</td></tr><tr><td align="center">redis-s1</td><td align="center">172.17.0.5</td><td align="center">16379</td></tr><tr><td align="center">redis-s2</td><td align="center">172.17.0.6</td><td align="center">16380</td></tr><tr><td align="center">redis-s3</td><td align="center">172.17.0.7</td><td align="center">16381</td></tr></tbody></table><p>在得到所有 Redis 容器的 IP地址后，回到 redis-m1 容器所在的命令窗口，进入容器内</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-m1 bash</span><br></pre></td></tr></table></figure><p>在其中用如下的命令连接该节点和其他节点。注意，这里的 IP地址 是 docker 容器工作的 IP地址，而不是 127.0.0.1</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 6379 cluster meet 172.17.0.3 6380</span><br><span class="line">redis-cli -p 6379 cluster meet 172.17.0.4 6381</span><br><span class="line">redis-cli -p 6379 cluster meet 172.17.0.5 16379</span><br><span class="line">redis-cli -p 6379 cluster meet 172.17.0.6 16380</span><br><span class="line">redis-cli -p 6379 cluster meet 172.17.0.7 16381</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 cluster meet 命令连接各个节点</span></span><br></pre></td></tr></table></figure><p>运行完成之后，进入 redis-m1 服务器内，再运行命令，就能看到如下所示的部分结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster info</span><br></pre></td></tr></table></figure><img src="https://i0.hdslb.com/bfs/album/654c132ed50f8f629153113f948cde94112f2b5d.png" alt="image-20221125125153579" style="zoom:80%;" /><p>输出里能看到当前 cluster 集群里有6个节点，集群处于 fail（失败）状态，原因是还没有给集群中的每个节点分配哈希槽，在后续步骤里将执行分配哈希槽的相关操作。</p><p>为三个主节点分配哈希槽。分配哈希槽的命令格式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 172.17.0.2 -p 6379 cluster addslots n</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数说明</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-h和-p指向Redis服务器节点，</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 cluster addslots 命令添加哈希槽，其中 n 是哈希槽的编号</span></span><br></pre></td></tr></table></figure><p>根据上面的描述，需要把0到5460号哈希槽分配到 redis-m1 节点上，如果要运行命令则需要运行5000多次，所以用如下名为 <code>setHashSlots.sh</code> 的脚本来分配，该脚本也是放在 <code>/opt/server</code> 目录里，以便各 docker 容器能映射到。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/server/setHashSlots.sh</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">for i in $(seq 0 5460)</span><br><span class="line">do</span><br><span class="line">/usr/local/bin/redis-cli -h 172.17.0.2 -p 6379 cluster addslots $i</span><br><span class="line">done</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /redisConfig/setHashSlots.sh</span><br></pre></td></tr></table></figure><p>随后更改 setHashSlots.sh 脚本里的哈希槽值和端口，到 redis-m2 所在的窗口里运行，为该节点分配 5461到10922号哈希槽。&#x3D;&#x3D;注意节点工作在6380端口，所以下面第3行 <code>-p</code> 后的值是 6380&#x3D;&#x3D;</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">for i in $(seq 5461 10922)</span><br><span class="line">do</span><br><span class="line">/usr/local/bin/redis-cli -h 172.17.0.3 -p 6380 cluster addslots $i</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>再次更改 setHashSlots.sh 脚本里的哈希槽值和端口，到 redis-m3 所在的窗口里运行，为该节点分配 10923 到 16383号哈希槽。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">for i in $(seq 10923 16383)</span><br><span class="line">do</span><br><span class="line">/usr/local/bin/redis-cli -h 172.17.0.4 -p 6381 cluster addslots $i</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>运行完成后，就可以把16384各哈希槽分配到3各主节点上了</p><div class="note danger simple"><p>错误提示说：slot 插槽被占用，，，，，，，</p><img src="https://i0.hdslb.com/bfs/album/5d4136be21a91329999350f827485c1b4a339ed8.png" alt="image-20221125141836989" style="zoom: 80%;" /><p>这是因为 搭建集群时，以前 redis 的旧数据和配置信息没有清理干净。</p><p>解决方案：</p><ul><li>用 redis-cli 登录到每个节点执行 <code>flushall</code> 和 <code>cluster reset</code> 就可以了</li></ul><img src="https://i0.hdslb.com/bfs/album/de7dcc2d5bd88cb207ead878d3a49ca86da5b0f3.png" alt="image-20221125142028242" style="zoom: 80%;" /></div><p>回到 redis-m1 所在的窗口，用 redis-cli 进入客户端后，再运行命令查看当前 cluster 集群的情况，能看到有如下的部分输出结果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster info</span><br></pre></td></tr></table></figure><img src="https://i0.hdslb.com/bfs/album/89baea729b75d792a31d4ae4f76c7d279ee74084.png" alt="image-20221125143305376" style="zoom:80%;" /><p>cluster_state:ok 确认该cluster集群工作正常，cluster_slots_assigned 与 cluster_slots_ok 确认 16384个哈希槽已经被分配到该 cluster 集群中。cluster_konwn_nodes 能确认当前 cluster 集群中有6个节点。</p><p>把cluster集群中的3个节点设置为“从”节点。设置从节点的方式是用 redis-cli 命令进入节点 redis 服务器，并运行 <code>cluster replicate &lt;对应主节点的node-id&gt;</code> 。</p><p>这里涉及一个问题：如何查看主节点的 node-id？回到 redis-m1 所在的命令行窗口，用 redis-cli 连接到服务器，再运行 <code>cluster nodes</code> 命令，虽然还没有设置主从关系，但是各节点已经互联，所以可以从运行结果里看到各节点的 node-id，相关操作如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster nodes</span><br></pre></td></tr></table></figure><img src="https://i0.hdslb.com/bfs/album/afebbe5e9c63fbc42169af1236bfb9c48109a4ba.png" alt="image-20221125143944782" style="zoom:80%;" /><p>从输出可以看出，<code>172.17.0.3:6380</code> 对应节点的 node-id 是 51e3……以此类推</p><p>得到各 node-id 后，可以进入 redis-s1 对应的命令行窗口，再通过命令进入该容器的命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-s1 /bin/bash</span><br><span class="line">redis-cli -p 16379</span><br></pre></td></tr></table></figure><p>随后设置主从关系，具体命令如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster replicate 284dadf30b64fd5b8e8015d9d3a14b982a4d2ed8</span><br></pre></td></tr></table></figure><p><code>cluster replicate</code> 命令后面跟随的参数是 172.17.0.2:6379 对应的 node-id，由此可以把 redis-s1 这个节点设置为 redis-m1 的从节点。进入 redis-s2 所在的命令行窗口，将 redis-s2 设置为 redis-m2的从节点</p><img src="https://i0.hdslb.com/bfs/album/99d70cb846288c3de03d8aebec5f7f4c41fd693f.png" alt="image-20221125152539883" style="zoom:80%;" /><h3 id="2-在cluster集群中读写数据"><a href="#2-在cluster集群中读写数据" class="headerlink" title="2 在cluster集群中读写数据"></a>2 在cluster集群中读写数据</h3><p>先用 <code>redis-cli -p 16381</code> 命令接入 redis-s3 所在的服务器，此时输入 set 命令，就能看到如下的错误提示信息</p><img src="https://i0.hdslb.com/bfs/album/bd2e2980d763cb8224b6312ddb3b2e563af94df6.png" alt="image-20221125153856259" style="zoom:80%;" /><p>根据之前描述的cluster集群的知识，在 set命令 时会先对键（name）进行 CRC16 运算，再根据结果把这个键放入对应的哈希槽所在的节点，从输出的错误信息可以看到，这个name键应该放入<code>172.17.0.3:6380</code> 哈希槽中</p><p>在实际操作中，用户希望是透明地进行数据的读写操作，而不希望看到此类的读写错误。</p><p>为了达到这个效果，需要在 redis-cli 命令后加入 -c 参数，以实现互联的效果，具体的命令及运行结果如下所示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 16381 -c</span><br></pre></td></tr></table></figure><img src="https://i0.hdslb.com/bfs/album/0d6cc2b98425940f89400adf98bc2701310fa475.png" alt="image-20221125154119117" style="zoom:80%;" /><p><code>redis-cli 命令</code> 后带了 -c 参数，所以当执行set命令时，虽然不该把name键放入本结点对应的哈希槽里，但是在cluster集群中的Redis服务器会自动把数据重新定位到 172.17.0.3:6380节点上。</p><p>同样使用 <code>get命令</code>时，虽然 name 键对应的数据没有存在该节点上，但可以读到name键对应的数据。这种“自动定位”带来的“读写透明”效果正是开发所需要的。</p><img src="https://i0.hdslb.com/bfs/album/8c09aa82bbf5ce04a6d9e7c9dfa247e221d187d0.png" alt="image-20221125154215381" style="zoom:80%;" /><p>如果将 redis-m2 节点暂停掉，然后用set命令设置键为name的数据，就会发现改建会被设置到其他节点上。也就是说，<strong>当节点失效后，cluster集群会自动再分配哈希槽，从而实现故障自动修复的效果</strong></p><h3 id="3-模拟扩容和数据迁移动作"><a href="#3-模拟扩容和数据迁移动作" class="headerlink" title="3 模拟扩容和数据迁移动作"></a>3 模拟扩容和数据迁移动作</h3><p>在上文的“三主三从”的cluster集群里，针对键的读写操作将会均摊到三个主节点上，比如当前针对Redis缓存的并发量是每秒 3000 次访问，那么均摊到三台主节点上的访问请求也就每秒1000次，也就是说cluster集群能很好地应对高并发带来的挑战。</p><p>随着项目业务量的增加，对cluster集群的访问压力有可能会增大，此时就需要通过向cluster集群里新增节点来承受更大的并发量。通过如下步骤，将会向上述搭建的“三主三从”的cluster集群里再增加一个主节点和一个从节点，以此实现扩容的效果。</p><p>在 <code>opt/server</code> 目录里，新增 cluster-mnew.conf 配置文件，用以配置新增主节点的信息，代码如下所示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 6385</span><br><span class="line">dir /redisConfig</span><br><span class="line">logfile cluster-mnew.log</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes-6385.conf</span><br></pre></td></tr></table></figure><p>随后用 <code>docker run 命令</code> 启动该容器以及其中的Redis 服务器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-mnew -v /opt/server:/redisConfig -p 6385:6385 redis:6.2.7 redis-server /redisConfig/cluster-mnew.conf</span><br></pre></td></tr></table></figure><p>启动后再执行 <code>docker inspect redis-mnew</code> 命令查看该Redis 服务器节点的 IP地址：172.17.0.8</p><img src="https://i0.hdslb.com/bfs/album/12e27370bb90151ccfdf68fe42bfae8d925b0ab1.png" alt="image-20221125162106462" style="zoom:80%;" /><p>在 <code>/opt/server</code> 目录里，新增 cluster-snew.conf 配置文件，用以配置新增从节点（将使用16385端口）的信息，配置文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">port 16385</span><br><span class="line">dir /redisConfig</span><br><span class="line">logfile cluster-snew.log</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes-16385.conf</span><br></pre></td></tr></table></figure><p>随后用如下的docker命令启动该容器以及其中的Redis服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name redis-snew -v /opt/server:/redisConfig -p 16385:16385 redis:6.2.7 redis-server /redisConfig/cluster-snew.conf</span><br></pre></td></tr></table></figure><p>启动后再执行 <code>docker inspect redis-snew</code> 命令查看该Redis 服务器节点的 IP地址：172.17.0.9</p><img src="https://i0.hdslb.com/bfs/album/410cd123ff63b74dc03e02c8e7e288f2035af15d.png" alt="image-20221125162210262" style="zoom:80%;" /><p>&#x3D;&#x3D;这里请注意，&#x3D;&#x3D;在cluster集群模式里不能通过slaveof的方式设置主从模式，所以需要先把节点加入cluster集群，再通过命令来设置主从关系。</p><p>通过 redis-cli 命令，进入 redis-m1 节点所对应的 Redis 服务器，再通过如下的两条命令把上述两个节点加入cluster集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cluster meet 172.17.0.8 6385</span><br><span class="line">cluster meet 172.17.0.9 16385</span><br></pre></td></tr></table></figure><p>通过 <code>cluster nodes</code> 查看节点ID</p><img src="https://i0.hdslb.com/bfs/album/b93dd3640734308bf2e7d0e1e3b9ecaced3c3327.png" alt="image-20221125170614859" style="zoom:80%;" /><div class="note info simple"><p>执行 <code>cluster nodes</code> 命令后，发现新加入的节点是从节点，如下图</p><img src="https://i0.hdslb.com/bfs/album/fc52f5ce534de598024920c1914e87cac4bce244.png" alt="image-20221125162530959" style="zoom:80%;" /><p>通过 redis-cli 进入redis-mnew 和 redis-snew命令窗体，执行 <code>cluster reset</code> 命令，重置节点</p></div><p>用 redis-cli 命令进入 <strong>redis-snew节点</strong>对应的 Redis服务器，设置主从关系</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-snew /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster replicate 55696860a746028bc0f0d3ff08a0eefaf3cad028</span><br></pre></td></tr></table></figure><p>cluster replicate 命令后跟的参数是 redis-mnew 节点对应的 node-id。</p><p>通过上述步骤，确实能把两个节点加入cluster集群中，但是没有分配哈希槽，所以这2个节点还无法真正地承载缓存数据。此时进入 <strong>redis-mnew 容器</strong>对应的命令行窗口，通过如下命令可以给 redis-mnew 节点分配哈希槽</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-mnew /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster reshard 172.17.0.2:6379 --cluster-from node-ID1,node-ID2,node-ID3 --cluster-to node-mn --cluster-slots 1024</span><br></pre></td></tr></table></figure><p>其中，reshard 后面的参数表示由这个redis服务器执行重新分配哈希槽的命令，–cluster-from 后面跟随的参数是原来3个主节点的node-id，即分配哈希槽的源节点，–cluster-to后面跟随的参数表示目标节点， –cluster-slots后面跟随的参数表示分配哈希槽的数量。</p><p>上述命令执行后会从原来三个主节点里各取1024个哈希槽分配到redis-mnew节点上，从而使该节点也能用哈希槽存放对应的键。</p><p>至此，完成了扩容动作。如果此时运行 <code>cluster info</code> 命令，就能看到如下所示的部分输出结果</p><img src="https://i0.hdslb.com/bfs/album/1550910eff6eea395fd7b8dc8972e558bd212490.png" alt="image-20221125183004851" style="zoom:80%;" /><p>cluster 集群中共有8个节点，“四主四从”结构</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redis高级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis初级</title>
      <link href="/posts/1d3045f4.html"/>
      <url>/posts/1d3045f4.html</url>
      
        <content type="html"><![CDATA[<h1 id="Redis初级"><a href="#Redis初级" class="headerlink" title="Redis初级"></a>Redis初级</h1><p>Redis 知识体系如下：</p><p><img src="https://pdai.tech/images/db/redis/db-redis-overview.png" alt="img"></p><p>本文只涉及“概念和基础”、“数据结构部分”两个章节，剩余内容在高级部分进行介绍。</p><h2 id="Redis-介绍"><a href="#Redis-介绍" class="headerlink" title="Redis 介绍"></a>Redis 介绍</h2><p>Redis 是一个开源的、基于Key-Value （键-值）存储的 NoSQL 数据库，是目前内存数据库方面的事实标准，是目前使用广泛的开源缓存中间件。</p><h3 id="Redis-特点"><a href="#Redis-特点" class="headerlink" title="Redis 特点"></a>Redis 特点</h3><ul><li>结构丰富，Redis 为用户提供了字符串、散列、列表、集合等一系列丰富的数据结构，每种数据结构都适用于解决特定的问题</li><li>速度飞快，Redis 是一款内存数据库，它将所有数据存储在内存中，与基于硬盘设计的传统数据库相比，Redis 在数据的存取速度方面具有天然的优势</li><li>功能完备，Redis提供了很多非常实用的功能，如自动过期、事务publish&#x2F;subscribe（发布&#x2F;订阅）等，能够将内存中的数据持久化保存在磁盘中，重启后再次将磁盘中的数据加载到内存。</li><li>扩展性强，Redis不仅可以单机使用，还可以多机使用，通过Redis自带的复制、集群功能，用户可以将自己的数据库扩展至任意大小。</li><li>使用方便，Redis提供了多种语言的API客户端，如Java、C&#x2F;C++、C#、PHP、JavaScript等。</li></ul><h3 id="NoSQL-数据库"><a href="#NoSQL-数据库" class="headerlink" title="NoSQL 数据库"></a>NoSQL 数据库</h3><ul><li>NoSQL，泛指非关系型的数据库</li><li>关系型数据库：如 MySQL、Oracle等，NoSQL数据库：Redis和MongoDB等</li><li>NoSQL 数据库种类繁多，但是一个共同特点就是去掉关系数据库的关系型特性，数据之间无关系，这样就非常容易扩展，同时具有非常高的读写性能。</li></ul><p><img src="https://i0.hdslb.com/bfs/album/2f40d0d4357d3f18845c1bcb06e251c5c38f9810.png" alt="image-20221123105401451"></p><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>本方法基于 CentOS7 系统安装 Redis 数据库</p><h3 id="安装步骤-1"><a href="#安装步骤-1" class="headerlink" title="安装步骤"></a>安装步骤</h3><ol><li>访问Redis的官方网站下载 redis 安装包：<a href="https://redis.io/download/">https://redis.io/download/</a></li><li>将 <code>redis-6.2.7.tar.gz</code> 安装包上传至 CentOS 系统</li><li>解压缩</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzf redis-6.2.7.tar.gz</span><br></pre></td></tr></table></figure><ol start="4"><li>进入 Redis 目录</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd redis-6.2.7</span><br></pre></td></tr></table></figure><ol start="5"><li>安装 gcc依赖，用于编译redis</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gcc tcl</span><br></pre></td></tr></table></figure><ol start="6"><li>运行编译命令</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><ol start="7"><li>默认被安装在 <code>/user/local/bin</code> 目录下</li></ol><h3 id="启动方式"><a href="#启动方式" class="headerlink" title="启动方式"></a>启动方式</h3><h4 id="前台启动"><a href="#前台启动" class="headerlink" title="前台启动"></a>前台启动</h4><p>通过运行安装目录中的 <code>redis-server</code> 启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在任意目录输入</span></span><br><span class="line">redis-server</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/album/c18f565159c8592bc2667e5742938234e3dc578b.png" alt="image-20221123111310858"></p><p>此种方式当关闭窗口或 ctrl + c 后，redis 就会停止</p><h4 id="后台启动"><a href="#后台启动" class="headerlink" title="后台启动"></a>后台启动</h4><p>若要后台启动 redis，需要修改配置文件 <code>redis.conf</code> ，此文件位于解压后的 redis 安装包下</p><p>修改 redis.conf，加入如下配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">允许访问的地址，默认是 127.0.0.1，会导致只能在本地访问。修改为 0.0.0.0 则可以在任意 IP访问，生产环境不要设置 0.0.0.0</span></span><br><span class="line">bind 0.0.0.0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">守护进程，修改为 <span class="built_in">yes</span> 后即可后台运行</span></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">密码，设置后访问 Redis 必须输入密码</span></span><br><span class="line">requirepass 123456</span><br></pre></td></tr></table></figure><p>除上述配置外，也可以设置端口号，最大占用内容，日志文件等内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">监听的端口</span></span><br><span class="line">port 6379</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置 redis 能够使用的最大内存</span></span><br><span class="line">maxmemory 512mb</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">日志文件，默认为空，不记录日志，可以指定日志文件名</span></span><br><span class="line">logfile &quot;redis.log&quot;</span><br></pre></td></tr></table></figure><p>通过指定配置文件启动 redis</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis.conf</span><br></pre></td></tr></table></figure><p>查看 redis 进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep redis</span><br></pre></td></tr></table></figure><p>停止服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-u 用于指定密码</span></span><br><span class="line">redis-cli -a 123456 shutdown</span><br></pre></td></tr></table></figure><h3 id="redis-客户端"><a href="#redis-客户端" class="headerlink" title="redis 客户端"></a>redis 客户端</h3><h4 id="命令行客户端"><a href="#命令行客户端" class="headerlink" title="命令行客户端"></a>命令行客户端</h4><p>通过 redis-cli 连接到本地 redis 数据库，-a 用于指定密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a 123456</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/album/94ecb6b74581f6a00e97a283b2c7544f21eb32c0.png" alt="image-20221123114343404"></p><h4 id="可视化客户端"><a href="#可视化客户端" class="headerlink" title="可视化客户端"></a>可视化客户端</h4><p>RedisDesktopManager 是一款开源的可视化Redis管理工具</p><p>地址：<a href="https://resp.app/">https://resp.app/</a> （在进行新版本开发，可能无法访问 2022.11.23）</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redis初级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot上传图片的两种方式</title>
      <link href="/posts/6a0d3409.html"/>
      <url>/posts/6a0d3409.html</url>
      
        <content type="html"><![CDATA[<h1 id="SpringBoot项目图片上传"><a href="#SpringBoot项目图片上传" class="headerlink" title="SpringBoot项目图片上传"></a>SpringBoot项目图片上传</h1><h2 id="搭建一个-SpringBoot-项目"><a href="#搭建一个-SpringBoot-项目" class="headerlink" title="搭建一个 SpringBoot 项目"></a>搭建一个 SpringBoot 项目</h2><ul><li>使用 Idea 搭建一个 SpringBoot 项目</li></ul><img src="https://i0.hdslb.com/bfs/album/4f0d269f92ae5371864e930209f723bfb74a9217.png" alt="image-20221119170916659" style="zoom:50%;" /><ul><li>在 pom.xml 中导入 web 依赖</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="将照片存储在项目的-Resource-目录下"><a href="#将照片存储在项目的-Resource-目录下" class="headerlink" title="将照片存储在项目的 Resource 目录下"></a>将照片存储在项目的 Resource 目录下</h2><ul><li>在Resource目录下有 images 文件夹和一个 static 文件夹，static下有一个upload.html文件，如下图</li></ul><p><img src="https://i0.hdslb.com/bfs/album/417885dbe8ca3ef552d0b79cbba2a077d4d97016.png" alt="image-20221119171657707"></p><ul><li>upload.html</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;/upload&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span> <span class="attr">enctype</span>=<span class="string">&quot;multipart/form-data&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">name</span>=<span class="string">&quot;file&quot;</span> <span class="attr">value</span>=<span class="string">&quot;请选择您要上传的照片&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">input</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;上传&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">input</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>UploaderController</p><p>为了方便演示，将业务放都在 controller 中，文件上传一般可分成：</p><ul><li>文件校验（包括不限于：图片的大小、图片的类型、图片是否为空、上传的是否是文件等）</li><li>将图片重命名，图片重命名又可分为以下几步<ul><li>获取原来文件的后缀名，可以使用<code>file.getOriginalFilename()</code>获取原来的文件名</li><li>生成一个随机的新文件名，这里可以使用<code>UUID.randomUUID()</code></li><li>把新名称和原后缀名拼接起来作为新的文件名</li></ul></li><li>把图片上传的指定的目录下，这里以Resource为例<ul><li><code>new ApplicationHome(this.getClass())</code>可以获取当前程序运行的主页</li><li>我们知道Java程序都是运行的.class字节码文件，所以<code>getDir()</code>获取文件夹位置其实是.class字节码文件的位置，需要使用<code>getParentFile()</code>两次回到项目的主目录</li><li>获取到主目录的绝对路径拼接上从这里到Resource下的images</li><li>最后通过<code>file.transferTo(new File(path));</code>把文件上传到Resource下的images目录，并且返回一个url地址</li></ul></li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> edu.cug.updateimg.controller;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> edu.cug.updateimg.util.UploadUtil;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.system.ApplicationHome;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.PostMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.multipart.MultipartFile;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*也可使用 Controller，但是需要再加 ResponseBody*/</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UploadController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/upload&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">upload</span><span class="params">(MultipartFile file)</span>&#123;</span><br><span class="line">        <span class="comment">// 图片校验（图片是否为空,图片大小，上传的是不是图片、图片类型（例如只能上传png）等等）</span></span><br><span class="line">        <span class="keyword">if</span>(file.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;图片文件格式错误&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 可以自己加一点校验 例如上传的是不是图片或者上传的文件是不是png格式等等 这里省略</span></span><br><span class="line">        <span class="comment">// 图片重命名，防止同命名文件相互覆盖</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">originalFilename</span> <span class="operator">=</span> file.getOriginalFilename(); <span class="comment">//  原来照片的名字</span></span><br><span class="line">        String[] temp = originalFilename.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">ext</span> <span class="operator">=</span> <span class="string">&quot;.&quot;</span> + temp[temp.length-<span class="number">1</span>];</span><br><span class="line">        <span class="type">String</span> <span class="variable">uuid</span> <span class="operator">=</span> UUID.randomUUID().toString().replace(<span class="string">&quot;-&quot;</span>,<span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">fileName</span> <span class="operator">=</span> uuid + ext;</span><br><span class="line">        <span class="comment">//上传图片</span></span><br><span class="line">        <span class="type">ApplicationHome</span> <span class="variable">applicationHome</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ApplicationHome</span>(<span class="built_in">this</span>.getClass());</span><br><span class="line">        <span class="type">String</span> <span class="variable">pre</span> <span class="operator">=</span> applicationHome.getDir().getParentFile().getParentFile().getAbsolutePath() +</span><br><span class="line">                <span class="string">&quot;/src/main/resources/images/&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">path</span> <span class="operator">=</span> pre + fileName;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            file.transferTo(<span class="keyword">new</span> <span class="title class_">File</span>(path));</span><br><span class="line">            <span class="keyword">return</span> path;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;照片上传失败&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><div class="note danger simple"><p>遇到如下错误</p><p><img src="https://i0.hdslb.com/bfs/album/d448ccfe28c19bd0b33597e34637763970eab645.png" alt="前端报错情况"></p><ul><li>错误出现的原因：跳转页面的 url 无对应的值<ul><li><b>Application</b> 启动类的位置不对。要将 Application 类放在最外层，即包含所有子包，因为 Spring-boot 会自动加载启动类所在包下及其子包的所有组件</li><li>在 SpringBoot 的配置文件： application.yml 和 application.properties 中关于视图解析器的配置问题：<ul><li>当 pom 文件下的 spring-boot-starter-parent 版本高时使用： spring.mvc.view.prefix&#x2F;spring.mvc.view.suffix</li><li>当 pom 文件下的 spring-boot-starter-parent 版本低时使用： spring.view.prefix&#x2F;spring.view.suffix</li></ul></li><li>控制器的 URL 路径书写问题。 @RequestMapping(“XXXXXX”)中的路径与实际访问路径不符合</li></ul></li></ul><p><img src="https://i0.hdslb.com/bfs/album/0312f27cf18b67192e9347b312c8fb5360edef55.png" alt="后端报错情况"></p><ul><li>错误出现原因：存储照片的路径中缺少某个或多个文件</li><li>解决方法：创建缺少的问题即可</li></ul></div><h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><ul><li>前端：返回上传照片的路径</li></ul><img src="https://i0.hdslb.com/bfs/album/6b913a46d47acfd85362f7bc7f808291dde65433.png" alt="image-20221119172845000" style="zoom:50%;" /><ul><li>成功上传到指定的 resource 文件夹下</li></ul><img src="https://i0.hdslb.com/bfs/album/204bd3ad7d630e75b43d26418ab7084d61858752.png" alt="image-20221119172937136" style="zoom:50%;" /><h2 id="OSS对象存储（以阿里云服务器为例）"><a href="#OSS对象存储（以阿里云服务器为例）" class="headerlink" title="OSS对象存储（以阿里云服务器为例）"></a>OSS对象存储（以阿里云服务器为例）</h2><img src="https://i0.hdslb.com/bfs/album/6ca616282e2daa80b4a31982db33badc1395ff2c.png" alt="image-20221117231501165" style="zoom:50%;" /><p>​因为目前多数项目为分布式服务，若将用户上传的文件（照片）存储在用户当前访问的服务器（如上图的服务器A）上，当用户下次通过别的服务器（服务器B C D ）提供服务时，则将无法读取到正确的已上传文件。针对这种情况，可以将用户上传的文件（照片）单独存储在另外一台存储服务器上，无论用户通过哪台服务器使用服务，都不会影响用户访问已上传文件。</p><ul><li>创建 Bucket<ul><li>名称：随便起</li><li>地域：想你的服务器在哪就选哪个（也是随便选）</li><li>存储类型：标准存储</li><li>冗余存储：关闭</li><li>版本控制：关闭</li><li>读写权限：公共读写</li></ul></li></ul><p>创建成功后的界面：</p><img src="https://i0.hdslb.com/bfs/album/bf354bfe3b090a60f7fa619daa78fe6a50bf0e7c.png" alt="image-20221119174131704" style="zoom: 50%;" /><ul><li><p>代码</p><ul><li>导入依赖</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.aliyun.oss<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>aliyun-sdk-oss<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-io<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-beanutils<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-beanutils<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>新建一个工具类UploadUtil在util包下</p><ul><li>需要获取几个参数<ul><li>阿里域名（开头加https:&#x2F;&#x2F;，结尾加&#x2F;）</li><li>地域节点（开头加http:&#x2F;&#x2F;）</li><li>accessKeyId</li><li>accessKeySecret</li></ul></li><li>生成一个新的文件名</li><li>使用OSS客户端对象上传图片返回url</li></ul><p>UploadUtil:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> edu.cug.updateimg.util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.aliyun.oss.OSS;</span><br><span class="line"><span class="keyword">import</span> com.aliyun.oss.OSSClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.io.FilenameUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.multipart.MultipartFile;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UploadUtil</span> &#123;</span><br><span class="line">    <span class="comment">// 阿里域名 + 存储文件名</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">ALI_DOMAIN</span> <span class="operator">=</span> <span class="string">&quot;https://liam-test.oss-cn-hangzhou.aliyuncs.com/&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">uploadImage</span><span class="params">(MultipartFile file)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// file 校验</span></span><br><span class="line">        <span class="keyword">if</span>(file.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;图片文件格式错误&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 生成文件名，防止file重命名，防止同命名文件相互覆盖</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">originalFilename</span> <span class="operator">=</span> file.getOriginalFilename(); <span class="comment">//  原来照片的名字</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">ext</span> <span class="operator">=</span> <span class="string">&quot;.&quot;</span> + FilenameUtils.getExtension(originalFilename);</span><br><span class="line">        <span class="type">String</span> <span class="variable">uuid</span> <span class="operator">=</span> UUID.randomUUID().toString().replace(<span class="string">&quot;-&quot;</span>,<span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">fileName</span> <span class="operator">=</span> <span class="string">&quot;demo/&quot;</span>+uuid + ext;</span><br><span class="line">        <span class="comment">// 地域结点</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">endpoint</span> <span class="operator">=</span> <span class="string">&quot;http://oss-cn-hangzhou.aliyuncs.com&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">accessKetId</span> <span class="operator">=</span> <span class="string">&quot;****&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">accessKeySecret</span> <span class="operator">=</span> <span class="string">&quot;****&quot;</span>;</span><br><span class="line">        <span class="comment">//OSS客户端对象</span></span><br><span class="line">        <span class="type">OSS</span> <span class="variable">ossClient</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OSSClient</span>(endpoint, accessKetId, accessKeySecret);</span><br><span class="line">        ossClient.putObject(</span><br><span class="line">                <span class="string">&quot;liam-test&quot;</span>, <span class="comment">//仓库名</span></span><br><span class="line">                fileName, <span class="comment">// 文件名</span></span><br><span class="line">                file.getInputStream()</span><br><span class="line">        );</span><br><span class="line">        ossClient.shutdown();</span><br><span class="line">        <span class="keyword">return</span> ALI_DOMAIN + fileName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>controller：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping(&quot;/upImg&quot;)</span></span><br><span class="line"><span class="keyword">public</span> String <span class="title function_">upImg</span><span class="params">(MultipartFile file)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="keyword">return</span> UploadUtil.uploadImage(file);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>upload.html：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;/upImg&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span> <span class="attr">enctype</span>=<span class="string">&quot;multipart/form-data&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">name</span>=<span class="string">&quot;file&quot;</span> <span class="attr">value</span>=<span class="string">&quot;上传图片&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;上传&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="运行结果-1"><a href="#运行结果-1" class="headerlink" title="运行结果"></a>运行结果</h3><ul><li>前端：返回上传照片的路径</li></ul><img src="https://i0.hdslb.com/bfs/album/16431b844e78f0cdaa6941dff2789eb6b87fcf19.png" alt="image-20221119174620478" style="zoom:50%;" /><ul><li>上传文件到指定阿里云文件夹下</li></ul><img src="https://i0.hdslb.com/bfs/album/b5fa8dd0b243b4ac99aaa8f544ec44a1258a768a.png" alt="image-20221119174724070" style="zoom:50%;" /><h2 id="使用API测试工具进行测试"><a href="#使用API测试工具进行测试" class="headerlink" title="使用API测试工具进行测试"></a>使用API测试工具进行测试</h2><ul><li><p>测试存储到 Resource 目录下</p><ul><li>设置请求头&#x3D;&#x3D;Content-Type&#x3D;multipart&#x2F;form-data&#x3D;&#x3D;</li></ul><p><img src="https://i0.hdslb.com/bfs/album/508e7d04c975090edd112eb9752c8a2fb57cd6e4.png" alt="image-20221119175533759"></p><ul><li>设置请求体</li></ul><p><img src="https://i0.hdslb.com/bfs/album/a52f7e03dde95ce16d8453fe4dabe14846caadcc.png" alt="image-20221119175711295"></p></li><li><p>测试 OSS 对象存储</p><ul><li>设置请求头&#x3D;&#x3D;Content-Type&#x3D;multipart&#x2F;form-data&#x3D;&#x3D;</li></ul><p><img src="https://i0.hdslb.com/bfs/album/bad67d65a093f1a2e452b8fecaa055a864e371b8.png" alt="image-20221119175049182"></p><ul><li>设置请求体</li></ul><p><img src="https://i0.hdslb.com/bfs/album/ccdb2a9ea6b0670ff6e1c52c4bb21b38af0b073e.png" alt="image-20221119175349975"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图片上传 </tag>
            
            <tag> SpringBoot </tag>
            
            <tag> OSS对象存储 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
